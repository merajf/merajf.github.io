{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7hknfgtRdn0n",
        "TRgApdoRLxr5"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merajf/merajf.github.io/blob/main/Assignment_3_DL_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKK5DA390wRe"
      },
      "source": [
        "# Prediction Challenge 3\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-rl2 --upgrade -q\n",
        "!pip install gym -q"
      ],
      "metadata": {
        "id": "a9tCXYD3j71D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c500a9-a721-44df-c7d5-a61bbb9d93ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.1 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rl\n",
        "from rl.memory import SequentialMemory  # import the exerience replay buffer module\n",
        "from rl.policy import EpsGreedyQPolicy  # import the policy\n",
        "from rl.policy import LinearAnnealedPolicy\n",
        "from rl.agents.dqn import DQNAgent      # import the DQN agent"
      ],
      "metadata": {
        "id": "trTr8Ywwh24U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0AMLzq08ap0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70f873d-2802-413b-d97d-ad1b1a0dd873"
      },
      "source": [
        "# load the gym module\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "# import the usual Keras modules for creating deep neural networks\n",
        "from keras import Sequential\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "ENV_NAME = 'CartPole-v0'\n",
        "env = gym.make(ENV_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.9/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Warm up 10 & No gamma value"
      ],
      "metadata": {
        "id": "Zk-mif2jeE1Q"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8ZiiRbxlH2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b489d0-81a4-4213-be6d-daa3ec3df154"
      },
      "source": [
        "\n",
        "# setup experience replay buffer\n",
        "# here the sequential memory limit is set up the same as the nb_steps (number of steps)\n",
        "# parameter in the fit method.  This means that all the action-states will fit into the\n",
        "# memory buffer\n",
        "# keep window_length as 1. It's used in other RL methods, but keep it to 1 in DQNs\n",
        "\n",
        "memory = SequentialMemory(limit=10000, window_length=1)\n",
        "\n",
        "policy =  LinearAnnealedPolicy(inner_policy=EpsGreedyQPolicy(0.2), \n",
        "                               attr='eps',            \n",
        "                               value_max=1.,\n",
        "                               value_min=.1, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=200)\n",
        "\n",
        "# Q-Network\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "# add extra layers here\n",
        "model.add(Flatten())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "print(model.summary())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_11 (Flatten)        (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 16)                80        \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 386\n",
            "Trainable params: 386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the agent\n",
        "dqn = DQNAgent(model=model,                   # Q-Network model\n",
        "               nb_actions=env.action_space.n, # number of actions\n",
        "               memory=memory,                 # experience replay memory\n",
        "               nb_steps_warmup=10,            # how many steps are waited before starting experience replay,\n",
        "               target_model_update=1e-2,      # how often the target network is updated\n",
        "               policy=policy)                 # the action selection policy\n",
        "\n",
        "dqn.compile(Adam(learning_rate=.0003), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eIPaCLWjoNET",
        "outputId": "20f209fb-cb8a-4c0c-a103-986882d0da98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 10 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 11 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 12 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 13 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 14 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 15 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 16 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 17 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 18 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 19 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 20 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 21 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 22 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 23 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 24 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 25 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 26 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 27 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 28 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 29 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 30 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   28/10000: episode: 1, duration: 6.439s, episode steps:  28, steps per second:   4, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 0.504225, mae: 0.520064, mean_q: 0.046803, mean_eps: 0.914500\n",
            "   46/10000: episode: 2, duration: 0.169s, episode steps:  18, steps per second: 106, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 0.507460, mae: 0.552046, mean_q: 0.150188, mean_eps: 0.835750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 31 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   77/10000: episode: 3, duration: 0.282s, episode steps:  31, steps per second: 110, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.419 [0.000, 1.000],  loss: 0.483564, mae: 0.561849, mean_q: 0.207288, mean_eps: 0.725500\n",
            "  132/10000: episode: 4, duration: 0.508s, episode steps:  55, steps per second: 108, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 0.454622, mae: 0.579936, mean_q: 0.288835, mean_eps: 0.532000\n",
            "  280/10000: episode: 5, duration: 1.359s, episode steps: 148, steps per second: 109, episode reward: 148.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 0.362579, mae: 0.624818, mean_q: 0.505239, mean_eps: 0.171331\n",
            "  478/10000: episode: 6, duration: 1.773s, episode steps: 198, steps per second: 112, episode reward: 198.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 0.223667, mae: 0.842120, mean_q: 1.178703, mean_eps: 0.100000\n",
            "  621/10000: episode: 7, duration: 1.284s, episode steps: 143, steps per second: 111, episode reward: 143.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 0.138818, mae: 1.288408, mean_q: 2.248476, mean_eps: 0.100000\n",
            "  673/10000: episode: 8, duration: 0.480s, episode steps:  52, steps per second: 108, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 0.130034, mae: 1.618539, mean_q: 2.941836, mean_eps: 0.100000\n",
            "  682/10000: episode: 9, duration: 0.087s, episode steps:   9, steps per second: 104, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 0.150332, mae: 1.722478, mean_q: 3.186150, mean_eps: 0.100000\n",
            "  691/10000: episode: 10, duration: 0.090s, episode steps:   9, steps per second: 100, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.111 [0.000, 1.000],  loss: 0.156120, mae: 1.800291, mean_q: 3.322906, mean_eps: 0.100000\n",
            "  701/10000: episode: 11, duration: 0.114s, episode steps:  10, steps per second:  87, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 0.315191, mae: 1.905821, mean_q: 3.462305, mean_eps: 0.100000\n",
            "  712/10000: episode: 12, duration: 0.113s, episode steps:  11, steps per second:  97, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.091 [0.000, 1.000],  loss: 0.366787, mae: 1.952769, mean_q: 3.511511, mean_eps: 0.100000\n",
            "  720/10000: episode: 13, duration: 0.081s, episode steps:   8, steps per second:  98, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 0.533077, mae: 2.010174, mean_q: 3.574438, mean_eps: 0.100000\n",
            "  801/10000: episode: 14, duration: 0.732s, episode steps:  81, steps per second: 111, episode reward: 81.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 0.353094, mae: 2.124130, mean_q: 3.851232, mean_eps: 0.100000\n",
            "  817/10000: episode: 15, duration: 0.157s, episode steps:  16, steps per second: 102, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 0.246255, mae: 2.250010, mean_q: 4.181660, mean_eps: 0.100000\n",
            "  829/10000: episode: 16, duration: 0.120s, episode steps:  12, steps per second: 100, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.917 [0.000, 1.000],  loss: 0.322139, mae: 2.337388, mean_q: 4.340002, mean_eps: 0.100000\n",
            "  894/10000: episode: 17, duration: 0.594s, episode steps:  65, steps per second: 109, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 0.325977, mae: 2.469803, mean_q: 4.616600, mean_eps: 0.100000\n",
            "  926/10000: episode: 18, duration: 0.444s, episode steps:  32, steps per second:  72, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 0.483947, mae: 2.676535, mean_q: 4.972347, mean_eps: 0.100000\n",
            "  936/10000: episode: 19, duration: 0.132s, episode steps:  10, steps per second:  76, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 0.365332, mae: 2.704056, mean_q: 5.086736, mean_eps: 0.100000\n",
            "  945/10000: episode: 20, duration: 0.131s, episode steps:   9, steps per second:  69, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.111 [0.000, 1.000],  loss: 0.405545, mae: 2.811618, mean_q: 5.233224, mean_eps: 0.100000\n",
            "  955/10000: episode: 21, duration: 0.138s, episode steps:  10, steps per second:  73, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 0.792101, mae: 2.900869, mean_q: 5.362604, mean_eps: 0.100000\n",
            "  971/10000: episode: 22, duration: 0.216s, episode steps:  16, steps per second:  74, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 0.705684, mae: 2.905614, mean_q: 5.355690, mean_eps: 0.100000\n",
            " 1095/10000: episode: 23, duration: 1.538s, episode steps: 124, steps per second:  81, episode reward: 124.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 0.650464, mae: 3.136828, mean_q: 5.867247, mean_eps: 0.100000\n",
            " 1109/10000: episode: 24, duration: 0.133s, episode steps:  14, steps per second: 105, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.716063, mae: 3.365005, mean_q: 6.351819, mean_eps: 0.100000\n",
            " 1130/10000: episode: 25, duration: 0.201s, episode steps:  21, steps per second: 105, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 0.581674, mae: 3.407956, mean_q: 6.447755, mean_eps: 0.100000\n",
            " 1171/10000: episode: 26, duration: 0.372s, episode steps:  41, steps per second: 110, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 0.695390, mae: 3.542567, mean_q: 6.715260, mean_eps: 0.100000\n",
            " 1194/10000: episode: 27, duration: 0.215s, episode steps:  23, steps per second: 107, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 0.493804, mae: 3.600622, mean_q: 6.870205, mean_eps: 0.100000\n",
            " 1205/10000: episode: 28, duration: 0.108s, episode steps:  11, steps per second: 102, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 0.756921, mae: 3.734774, mean_q: 7.160530, mean_eps: 0.100000\n",
            " 1218/10000: episode: 29, duration: 0.140s, episode steps:  13, steps per second:  93, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 0.529762, mae: 3.741009, mean_q: 7.177446, mean_eps: 0.100000\n",
            " 1234/10000: episode: 30, duration: 0.166s, episode steps:  16, steps per second:  97, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.028832, mae: 3.850973, mean_q: 7.268244, mean_eps: 0.100000\n",
            " 1270/10000: episode: 31, duration: 0.332s, episode steps:  36, steps per second: 108, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 0.763877, mae: 3.904955, mean_q: 7.399976, mean_eps: 0.100000\n",
            " 1297/10000: episode: 32, duration: 0.255s, episode steps:  27, steps per second: 106, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 0.792944, mae: 3.987869, mean_q: 7.572944, mean_eps: 0.100000\n",
            " 1314/10000: episode: 33, duration: 0.155s, episode steps:  17, steps per second: 110, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 0.917692, mae: 4.111981, mean_q: 7.775780, mean_eps: 0.100000\n",
            " 1336/10000: episode: 34, duration: 0.203s, episode steps:  22, steps per second: 109, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 0.578228, mae: 4.114761, mean_q: 7.876670, mean_eps: 0.100000\n",
            " 1362/10000: episode: 35, duration: 0.231s, episode steps:  26, steps per second: 113, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 0.737151, mae: 4.203404, mean_q: 8.075604, mean_eps: 0.100000\n",
            " 1381/10000: episode: 36, duration: 0.173s, episode steps:  19, steps per second: 110, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 1.092995, mae: 4.334137, mean_q: 8.237857, mean_eps: 0.100000\n",
            " 1392/10000: episode: 37, duration: 0.127s, episode steps:  11, steps per second:  86, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.636 [0.000, 1.000],  loss: 0.621943, mae: 4.285829, mean_q: 8.297028, mean_eps: 0.100000\n",
            " 1402/10000: episode: 38, duration: 0.100s, episode steps:  10, steps per second: 100, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 0.801850, mae: 4.367073, mean_q: 8.505010, mean_eps: 0.100000\n",
            " 1411/10000: episode: 39, duration: 0.088s, episode steps:   9, steps per second: 102, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.614856, mae: 4.380406, mean_q: 8.531388, mean_eps: 0.100000\n",
            " 1432/10000: episode: 40, duration: 0.190s, episode steps:  21, steps per second: 110, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 1.024906, mae: 4.528562, mean_q: 8.688069, mean_eps: 0.100000\n",
            " 1449/10000: episode: 41, duration: 0.160s, episode steps:  17, steps per second: 106, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 1.202575, mae: 4.582545, mean_q: 8.665191, mean_eps: 0.100000\n",
            " 1463/10000: episode: 42, duration: 0.139s, episode steps:  14, steps per second: 101, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 0.978570, mae: 4.634016, mean_q: 8.837697, mean_eps: 0.100000\n",
            " 1473/10000: episode: 43, duration: 0.096s, episode steps:  10, steps per second: 105, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 0.359230, mae: 4.610704, mean_q: 9.061277, mean_eps: 0.100000\n",
            " 1482/10000: episode: 44, duration: 0.092s, episode steps:   9, steps per second:  97, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: 1.914543, mae: 4.816098, mean_q: 9.160445, mean_eps: 0.100000\n",
            " 1493/10000: episode: 45, duration: 0.114s, episode steps:  11, steps per second:  96, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.909 [0.000, 1.000],  loss: 1.246113, mae: 4.791668, mean_q: 9.203331, mean_eps: 0.100000\n",
            " 1503/10000: episode: 46, duration: 0.096s, episode steps:  10, steps per second: 105, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: 1.523386, mae: 4.890010, mean_q: 9.327074, mean_eps: 0.100000\n",
            " 1515/10000: episode: 47, duration: 0.121s, episode steps:  12, steps per second:  99, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 1.252709, mae: 4.876618, mean_q: 9.246849, mean_eps: 0.100000\n",
            " 1527/10000: episode: 48, duration: 0.114s, episode steps:  12, steps per second: 105, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 1.228876, mae: 4.907876, mean_q: 9.349539, mean_eps: 0.100000\n",
            " 1537/10000: episode: 49, duration: 0.103s, episode steps:  10, steps per second:  97, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: 1.724855, mae: 4.987523, mean_q: 9.416828, mean_eps: 0.100000\n",
            " 1546/10000: episode: 50, duration: 0.086s, episode steps:   9, steps per second: 104, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: 1.056420, mae: 4.959490, mean_q: 9.452515, mean_eps: 0.100000\n",
            " 1556/10000: episode: 51, duration: 0.093s, episode steps:  10, steps per second: 108, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: 1.338819, mae: 5.035614, mean_q: 9.606997, mean_eps: 0.100000\n",
            " 1568/10000: episode: 52, duration: 0.115s, episode steps:  12, steps per second: 104, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.917 [0.000, 1.000],  loss: 1.732762, mae: 5.094240, mean_q: 9.666382, mean_eps: 0.100000\n",
            " 1577/10000: episode: 53, duration: 0.087s, episode steps:   9, steps per second: 104, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: 2.765538, mae: 5.282125, mean_q: 9.783113, mean_eps: 0.100000\n",
            " 1586/10000: episode: 54, duration: 0.087s, episode steps:   9, steps per second: 104, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 1.459901, mae: 5.159306, mean_q: 9.677313, mean_eps: 0.100000\n",
            " 1596/10000: episode: 55, duration: 0.109s, episode steps:  10, steps per second:  92, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: 1.376329, mae: 5.195579, mean_q: 9.776127, mean_eps: 0.100000\n",
            " 1608/10000: episode: 56, duration: 0.114s, episode steps:  12, steps per second: 105, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.917 [0.000, 1.000],  loss: 1.963545, mae: 5.283750, mean_q: 9.961197, mean_eps: 0.100000\n",
            " 1620/10000: episode: 57, duration: 0.112s, episode steps:  12, steps per second: 107, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.833 [0.000, 1.000],  loss: 2.211152, mae: 5.354264, mean_q: 10.020344, mean_eps: 0.100000\n",
            " 1629/10000: episode: 58, duration: 0.093s, episode steps:   9, steps per second:  97, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: 2.163536, mae: 5.363528, mean_q: 10.003754, mean_eps: 0.100000\n",
            " 1641/10000: episode: 59, duration: 0.115s, episode steps:  12, steps per second: 104, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.833 [0.000, 1.000],  loss: 1.225233, mae: 5.305762, mean_q: 10.055959, mean_eps: 0.100000\n",
            " 1650/10000: episode: 60, duration: 0.087s, episode steps:   9, steps per second: 104, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: 1.700081, mae: 5.388477, mean_q: 10.176173, mean_eps: 0.100000\n",
            " 1663/10000: episode: 61, duration: 0.124s, episode steps:  13, steps per second: 105, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.769 [0.000, 1.000],  loss: 1.564426, mae: 5.392114, mean_q: 10.270383, mean_eps: 0.100000\n",
            " 1672/10000: episode: 62, duration: 0.088s, episode steps:   9, steps per second: 102, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: 1.894029, mae: 5.498435, mean_q: 10.327218, mean_eps: 0.100000\n",
            " 1682/10000: episode: 63, duration: 0.100s, episode steps:  10, steps per second: 100, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 1.381930, mae: 5.453669, mean_q: 10.406725, mean_eps: 0.100000\n",
            " 1691/10000: episode: 64, duration: 0.094s, episode steps:   9, steps per second:  96, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 1.284194, mae: 5.471353, mean_q: 10.477873, mean_eps: 0.100000\n",
            " 1700/10000: episode: 65, duration: 0.095s, episode steps:   9, steps per second:  95, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 1.758270, mae: 5.607786, mean_q: 10.676438, mean_eps: 0.100000\n",
            " 1709/10000: episode: 66, duration: 0.095s, episode steps:   9, steps per second:  95, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.889 [0.000, 1.000],  loss: 1.239978, mae: 5.566339, mean_q: 10.678022, mean_eps: 0.100000\n",
            " 1720/10000: episode: 67, duration: 0.109s, episode steps:  11, steps per second: 101, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 2.136255, mae: 5.684823, mean_q: 10.736005, mean_eps: 0.100000\n",
            " 1730/10000: episode: 68, duration: 0.108s, episode steps:  10, steps per second:  92, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: 1.914955, mae: 5.669829, mean_q: 10.710276, mean_eps: 0.100000\n",
            " 1741/10000: episode: 69, duration: 0.119s, episode steps:  11, steps per second:  92, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 2.477506, mae: 5.757329, mean_q: 10.729556, mean_eps: 0.100000\n",
            " 1750/10000: episode: 70, duration: 0.094s, episode steps:   9, steps per second:  96, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: 2.478309, mae: 5.750913, mean_q: 10.646138, mean_eps: 0.100000\n",
            " 1761/10000: episode: 71, duration: 0.117s, episode steps:  11, steps per second:  94, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 2.215344, mae: 5.752377, mean_q: 10.656260, mean_eps: 0.100000\n",
            " 1774/10000: episode: 72, duration: 0.132s, episode steps:  13, steps per second:  98, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 2.235067, mae: 5.816675, mean_q: 10.788873, mean_eps: 0.100000\n",
            " 1788/10000: episode: 73, duration: 0.137s, episode steps:  14, steps per second: 102, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 1.328805, mae: 5.773457, mean_q: 10.886300, mean_eps: 0.100000\n",
            " 1803/10000: episode: 74, duration: 0.144s, episode steps:  15, steps per second: 104, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 1.344987, mae: 5.782178, mean_q: 11.027029, mean_eps: 0.100000\n",
            " 1816/10000: episode: 75, duration: 0.122s, episode steps:  13, steps per second: 106, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 2.200507, mae: 5.885087, mean_q: 11.104308, mean_eps: 0.100000\n",
            " 1826/10000: episode: 76, duration: 0.104s, episode steps:  10, steps per second:  96, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 1.915027, mae: 5.931436, mean_q: 11.201536, mean_eps: 0.100000\n",
            " 1837/10000: episode: 77, duration: 0.103s, episode steps:  11, steps per second: 107, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 2.508682, mae: 5.929482, mean_q: 10.965725, mean_eps: 0.100000\n",
            " 1848/10000: episode: 78, duration: 0.105s, episode steps:  11, steps per second: 105, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 1.892559, mae: 5.900310, mean_q: 10.985519, mean_eps: 0.100000\n",
            " 1861/10000: episode: 79, duration: 0.128s, episode steps:  13, steps per second: 101, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.846 [0.000, 1.000],  loss: 2.655609, mae: 6.029077, mean_q: 11.191999, mean_eps: 0.100000\n",
            " 1870/10000: episode: 80, duration: 0.094s, episode steps:   9, steps per second:  95, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 2.239178, mae: 5.957184, mean_q: 11.126181, mean_eps: 0.100000\n",
            " 1880/10000: episode: 81, duration: 0.097s, episode steps:  10, steps per second: 103, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: 2.514953, mae: 6.079805, mean_q: 11.293819, mean_eps: 0.100000\n",
            " 1889/10000: episode: 82, duration: 0.095s, episode steps:   9, steps per second:  95, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 3.625302, mae: 6.184511, mean_q: 11.278078, mean_eps: 0.100000\n",
            " 1898/10000: episode: 83, duration: 0.096s, episode steps:   9, steps per second:  94, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: 1.928335, mae: 5.969463, mean_q: 11.042485, mean_eps: 0.100000\n",
            " 1906/10000: episode: 84, duration: 0.081s, episode steps:   8, steps per second:  99, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 1.926625, mae: 6.075168, mean_q: 11.191634, mean_eps: 0.100000\n",
            " 1915/10000: episode: 85, duration: 0.092s, episode steps:   9, steps per second:  98, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.778 [0.000, 1.000],  loss: 1.900451, mae: 6.072575, mean_q: 11.352472, mean_eps: 0.100000\n",
            " 1928/10000: episode: 86, duration: 0.123s, episode steps:  13, steps per second: 105, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 1.303001, mae: 6.003157, mean_q: 11.385634, mean_eps: 0.100000\n",
            " 1936/10000: episode: 87, duration: 0.092s, episode steps:   8, steps per second:  87, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.875 [0.000, 1.000],  loss: 2.314729, mae: 6.118860, mean_q: 11.439193, mean_eps: 0.100000\n",
            " 1949/10000: episode: 88, duration: 0.121s, episode steps:  13, steps per second: 107, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 2.608811, mae: 6.161599, mean_q: 11.382124, mean_eps: 0.100000\n",
            " 1962/10000: episode: 89, duration: 0.121s, episode steps:  13, steps per second: 107, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.692 [0.000, 1.000],  loss: 2.068172, mae: 6.132419, mean_q: 11.397200, mean_eps: 0.100000\n",
            " 1973/10000: episode: 90, duration: 0.107s, episode steps:  11, steps per second: 103, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 2.210931, mae: 6.116786, mean_q: 11.432810, mean_eps: 0.100000\n",
            " 1982/10000: episode: 91, duration: 0.086s, episode steps:   9, steps per second: 105, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 1.867663, mae: 6.160820, mean_q: 11.530993, mean_eps: 0.100000\n",
            " 1991/10000: episode: 92, duration: 0.090s, episode steps:   9, steps per second:  99, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 2.759027, mae: 6.232248, mean_q: 11.515766, mean_eps: 0.100000\n",
            " 2008/10000: episode: 93, duration: 0.162s, episode steps:  17, steps per second: 105, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 2.380956, mae: 6.242659, mean_q: 11.575062, mean_eps: 0.100000\n",
            " 2047/10000: episode: 94, duration: 0.355s, episode steps:  39, steps per second: 110, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.564 [0.000, 1.000],  loss: 1.934900, mae: 6.249828, mean_q: 11.697756, mean_eps: 0.100000\n",
            " 2061/10000: episode: 95, duration: 0.137s, episode steps:  14, steps per second: 102, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.214 [0.000, 1.000],  loss: 1.941909, mae: 6.285590, mean_q: 11.857684, mean_eps: 0.100000\n",
            " 2069/10000: episode: 96, duration: 0.082s, episode steps:   8, steps per second:  98, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 1.908437, mae: 6.249173, mean_q: 11.783410, mean_eps: 0.100000\n",
            " 2079/10000: episode: 97, duration: 0.095s, episode steps:  10, steps per second: 105, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 2.115160, mae: 6.327579, mean_q: 11.858974, mean_eps: 0.100000\n",
            " 2089/10000: episode: 98, duration: 0.100s, episode steps:  10, steps per second: 100, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 2.186388, mae: 6.350029, mean_q: 11.931554, mean_eps: 0.100000\n",
            " 2099/10000: episode: 99, duration: 0.099s, episode steps:  10, steps per second: 101, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 1.294296, mae: 6.265617, mean_q: 11.821284, mean_eps: 0.100000\n",
            " 2107/10000: episode: 100, duration: 0.111s, episode steps:   8, steps per second:  72, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.125 [0.000, 1.000],  loss: 0.874262, mae: 6.276310, mean_q: 11.974018, mean_eps: 0.100000\n",
            " 2120/10000: episode: 101, duration: 0.199s, episode steps:  13, steps per second:  65, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.231 [0.000, 1.000],  loss: 2.033255, mae: 6.436529, mean_q: 12.144532, mean_eps: 0.100000\n",
            " 2159/10000: episode: 102, duration: 0.525s, episode steps:  39, steps per second:  74, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 1.919153, mae: 6.472952, mean_q: 12.214198, mean_eps: 0.100000\n",
            " 2168/10000: episode: 103, duration: 0.126s, episode steps:   9, steps per second:  72, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.111 [0.000, 1.000],  loss: 2.041067, mae: 6.536307, mean_q: 12.350581, mean_eps: 0.100000\n",
            " 2178/10000: episode: 104, duration: 0.164s, episode steps:  10, steps per second:  61, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 2.487501, mae: 6.534423, mean_q: 12.234716, mean_eps: 0.100000\n",
            " 2189/10000: episode: 105, duration: 0.155s, episode steps:  11, steps per second:  71, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.091 [0.000, 1.000],  loss: 2.787535, mae: 6.608393, mean_q: 12.298689, mean_eps: 0.100000\n",
            " 2198/10000: episode: 106, duration: 0.129s, episode steps:   9, steps per second:  70, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 2.547132, mae: 6.653546, mean_q: 12.398090, mean_eps: 0.100000\n",
            " 2237/10000: episode: 107, duration: 0.527s, episode steps:  39, steps per second:  74, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.436 [0.000, 1.000],  loss: 2.657832, mae: 6.651693, mean_q: 12.337183, mean_eps: 0.100000\n",
            " 2245/10000: episode: 108, duration: 0.123s, episode steps:   8, steps per second:  65, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 3.377439, mae: 6.718883, mean_q: 12.366002, mean_eps: 0.100000\n",
            " 2254/10000: episode: 109, duration: 0.137s, episode steps:   9, steps per second:  66, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 1.407157, mae: 6.536962, mean_q: 12.399238, mean_eps: 0.100000\n",
            " 2263/10000: episode: 110, duration: 0.131s, episode steps:   9, steps per second:  69, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 2.893332, mae: 6.706191, mean_q: 12.551322, mean_eps: 0.100000\n",
            " 2272/10000: episode: 111, duration: 0.135s, episode steps:   9, steps per second:  67, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 2.912334, mae: 6.812771, mean_q: 12.773242, mean_eps: 0.100000\n",
            " 2281/10000: episode: 112, duration: 0.126s, episode steps:   9, steps per second:  71, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 1.785730, mae: 6.633623, mean_q: 12.525187, mean_eps: 0.100000\n",
            " 2289/10000: episode: 113, duration: 0.084s, episode steps:   8, steps per second:  95, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 1.753600, mae: 6.686439, mean_q: 12.708776, mean_eps: 0.100000\n",
            " 2298/10000: episode: 114, duration: 0.090s, episode steps:   9, steps per second: 100, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 1.747050, mae: 6.808843, mean_q: 12.986933, mean_eps: 0.100000\n",
            " 2310/10000: episode: 115, duration: 0.118s, episode steps:  12, steps per second: 102, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.083 [0.000, 1.000],  loss: 2.975309, mae: 6.903408, mean_q: 12.970684, mean_eps: 0.100000\n",
            " 2345/10000: episode: 116, duration: 0.327s, episode steps:  35, steps per second: 107, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 2.284099, mae: 6.800039, mean_q: 12.721330, mean_eps: 0.100000\n",
            " 2381/10000: episode: 117, duration: 0.333s, episode steps:  36, steps per second: 108, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.389 [0.000, 1.000],  loss: 2.708801, mae: 6.862932, mean_q: 12.756642, mean_eps: 0.100000\n",
            " 2419/10000: episode: 118, duration: 0.349s, episode steps:  38, steps per second: 109, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.553 [0.000, 1.000],  loss: 2.595501, mae: 6.907896, mean_q: 12.808790, mean_eps: 0.100000\n",
            " 2455/10000: episode: 119, duration: 0.340s, episode steps:  36, steps per second: 106, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.616501, mae: 6.918320, mean_q: 13.107164, mean_eps: 0.100000\n",
            " 2474/10000: episode: 120, duration: 0.176s, episode steps:  19, steps per second: 108, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: 2.340081, mae: 7.035204, mean_q: 13.371785, mean_eps: 0.100000\n",
            " 2486/10000: episode: 121, duration: 0.131s, episode steps:  12, steps per second:  92, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 2.516417, mae: 7.057790, mean_q: 13.331002, mean_eps: 0.100000\n",
            " 2496/10000: episode: 122, duration: 0.101s, episode steps:  10, steps per second:  99, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.300 [0.000, 1.000],  loss: 2.219013, mae: 7.010387, mean_q: 13.234753, mean_eps: 0.100000\n",
            " 2509/10000: episode: 123, duration: 0.127s, episode steps:  13, steps per second: 103, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 2.491093, mae: 7.116061, mean_q: 13.416744, mean_eps: 0.100000\n",
            " 2535/10000: episode: 124, duration: 0.243s, episode steps:  26, steps per second: 107, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 3.103546, mae: 7.132811, mean_q: 13.273302, mean_eps: 0.100000\n",
            " 2544/10000: episode: 125, duration: 0.091s, episode steps:   9, steps per second:  99, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 2.441691, mae: 7.074319, mean_q: 13.233165, mean_eps: 0.100000\n",
            " 2557/10000: episode: 126, duration: 0.130s, episode steps:  13, steps per second: 100, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 2.280853, mae: 7.158391, mean_q: 13.545363, mean_eps: 0.100000\n",
            " 2570/10000: episode: 127, duration: 0.124s, episode steps:  13, steps per second: 105, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 2.853769, mae: 7.090992, mean_q: 13.255760, mean_eps: 0.100000\n",
            " 2591/10000: episode: 128, duration: 0.203s, episode steps:  21, steps per second: 104, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 3.002277, mae: 7.141419, mean_q: 13.308451, mean_eps: 0.100000\n",
            " 2636/10000: episode: 129, duration: 0.426s, episode steps:  45, steps per second: 106, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 2.168317, mae: 7.180469, mean_q: 13.500528, mean_eps: 0.100000\n",
            " 2684/10000: episode: 130, duration: 0.441s, episode steps:  48, steps per second: 109, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.243278, mae: 7.224908, mean_q: 13.620471, mean_eps: 0.100000\n",
            " 2718/10000: episode: 131, duration: 0.318s, episode steps:  34, steps per second: 107, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.282636, mae: 7.247051, mean_q: 13.637666, mean_eps: 0.100000\n",
            " 2751/10000: episode: 132, duration: 0.305s, episode steps:  33, steps per second: 108, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 2.214107, mae: 7.357589, mean_q: 13.932516, mean_eps: 0.100000\n",
            " 2786/10000: episode: 133, duration: 0.335s, episode steps:  35, steps per second: 105, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 2.286128, mae: 7.364061, mean_q: 13.889782, mean_eps: 0.100000\n",
            " 2809/10000: episode: 134, duration: 0.206s, episode steps:  23, steps per second: 112, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 1.832035, mae: 7.458800, mean_q: 14.221378, mean_eps: 0.100000\n",
            " 2842/10000: episode: 135, duration: 0.294s, episode steps:  33, steps per second: 112, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 1.965412, mae: 7.525722, mean_q: 14.355062, mean_eps: 0.100000\n",
            " 2921/10000: episode: 136, duration: 0.720s, episode steps:  79, steps per second: 110, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 2.292251, mae: 7.620522, mean_q: 14.438068, mean_eps: 0.100000\n",
            " 2957/10000: episode: 137, duration: 0.334s, episode steps:  36, steps per second: 108, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.433269, mae: 7.772628, mean_q: 14.713182, mean_eps: 0.100000\n",
            " 3000/10000: episode: 138, duration: 0.412s, episode steps:  43, steps per second: 104, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 2.079714, mae: 7.746209, mean_q: 14.706708, mean_eps: 0.100000\n",
            " 3053/10000: episode: 139, duration: 0.481s, episode steps:  53, steps per second: 110, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 2.653334, mae: 7.810988, mean_q: 14.760430, mean_eps: 0.100000\n",
            " 3094/10000: episode: 140, duration: 0.372s, episode steps:  41, steps per second: 110, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 2.509610, mae: 7.901564, mean_q: 14.996889, mean_eps: 0.100000\n",
            " 3147/10000: episode: 141, duration: 0.486s, episode steps:  53, steps per second: 109, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 2.422172, mae: 7.923753, mean_q: 15.043225, mean_eps: 0.100000\n",
            " 3195/10000: episode: 142, duration: 0.453s, episode steps:  48, steps per second: 106, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 2.245652, mae: 8.073384, mean_q: 15.368970, mean_eps: 0.100000\n",
            " 3263/10000: episode: 143, duration: 0.620s, episode steps:  68, steps per second: 110, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 2.137784, mae: 8.093579, mean_q: 15.399462, mean_eps: 0.100000\n",
            " 3312/10000: episode: 144, duration: 0.462s, episode steps:  49, steps per second: 106, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 2.154047, mae: 8.296767, mean_q: 15.843980, mean_eps: 0.100000\n",
            " 3361/10000: episode: 145, duration: 0.538s, episode steps:  49, steps per second:  91, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 2.620311, mae: 8.407303, mean_q: 16.018357, mean_eps: 0.100000\n",
            " 3526/10000: episode: 146, duration: 2.121s, episode steps: 165, steps per second:  78, episode reward: 165.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 2.631488, mae: 8.586183, mean_q: 16.369125, mean_eps: 0.100000\n",
            " 3627/10000: episode: 147, duration: 0.933s, episode steps: 101, steps per second: 108, episode reward: 101.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 2.315838, mae: 8.854006, mean_q: 17.003849, mean_eps: 0.100000\n",
            " 3662/10000: episode: 148, duration: 0.328s, episode steps:  35, steps per second: 107, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 2.735731, mae: 9.029584, mean_q: 17.366392, mean_eps: 0.100000\n",
            " 3724/10000: episode: 149, duration: 0.594s, episode steps:  62, steps per second: 104, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 2.515939, mae: 9.045904, mean_q: 17.338190, mean_eps: 0.100000\n",
            " 3798/10000: episode: 150, duration: 0.703s, episode steps:  74, steps per second: 105, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 2.406635, mae: 9.158752, mean_q: 17.629959, mean_eps: 0.100000\n",
            " 3860/10000: episode: 151, duration: 0.567s, episode steps:  62, steps per second: 109, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 3.511803, mae: 9.384738, mean_q: 17.921141, mean_eps: 0.100000\n",
            " 3898/10000: episode: 152, duration: 0.348s, episode steps:  38, steps per second: 109, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 3.286370, mae: 9.405163, mean_q: 18.030241, mean_eps: 0.100000\n",
            " 3936/10000: episode: 153, duration: 0.353s, episode steps:  38, steps per second: 108, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 3.850635, mae: 9.572231, mean_q: 18.278230, mean_eps: 0.100000\n",
            " 4024/10000: episode: 154, duration: 0.798s, episode steps:  88, steps per second: 110, episode reward: 88.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 2.212658, mae: 9.650674, mean_q: 18.625364, mean_eps: 0.100000\n",
            " 4075/10000: episode: 155, duration: 0.476s, episode steps:  51, steps per second: 107, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 3.655049, mae: 9.848253, mean_q: 18.886103, mean_eps: 0.100000\n",
            " 4144/10000: episode: 156, duration: 0.625s, episode steps:  69, steps per second: 110, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 4.109909, mae: 9.947545, mean_q: 18.998936, mean_eps: 0.100000\n",
            " 4185/10000: episode: 157, duration: 0.372s, episode steps:  41, steps per second: 110, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 2.739383, mae: 9.933287, mean_q: 19.105597, mean_eps: 0.100000\n",
            " 4385/10000: episode: 158, duration: 1.806s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 3.130213, mae: 10.245982, mean_q: 19.739370, mean_eps: 0.100000\n",
            " 4438/10000: episode: 159, duration: 0.487s, episode steps:  53, steps per second: 109, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 3.676634, mae: 10.513759, mean_q: 20.258247, mean_eps: 0.100000\n",
            " 4474/10000: episode: 160, duration: 0.339s, episode steps:  36, steps per second: 106, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 4.003379, mae: 10.588019, mean_q: 20.379589, mean_eps: 0.100000\n",
            " 4561/10000: episode: 161, duration: 0.781s, episode steps:  87, steps per second: 111, episode reward: 87.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 2.753412, mae: 10.682129, mean_q: 20.720187, mean_eps: 0.100000\n",
            " 4643/10000: episode: 162, duration: 0.834s, episode steps:  82, steps per second:  98, episode reward: 82.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 3.669969, mae: 10.980683, mean_q: 21.220607, mean_eps: 0.100000\n",
            " 4824/10000: episode: 163, duration: 2.308s, episode steps: 181, steps per second:  78, episode reward: 181.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 3.590246, mae: 11.177021, mean_q: 21.618992, mean_eps: 0.100000\n",
            " 4967/10000: episode: 164, duration: 1.301s, episode steps: 143, steps per second: 110, episode reward: 143.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 3.966009, mae: 11.472255, mean_q: 22.196652, mean_eps: 0.100000\n",
            " 5045/10000: episode: 165, duration: 0.715s, episode steps:  78, steps per second: 109, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 3.775813, mae: 11.646118, mean_q: 22.582540, mean_eps: 0.100000\n",
            " 5141/10000: episode: 166, duration: 0.881s, episode steps:  96, steps per second: 109, episode reward: 96.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 3.435851, mae: 11.780242, mean_q: 22.882359, mean_eps: 0.100000\n",
            " 5231/10000: episode: 167, duration: 0.812s, episode steps:  90, steps per second: 111, episode reward: 90.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 3.278430, mae: 12.027481, mean_q: 23.434805, mean_eps: 0.100000\n",
            " 5350/10000: episode: 168, duration: 1.089s, episode steps: 119, steps per second: 109, episode reward: 119.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 4.899673, mae: 12.249683, mean_q: 23.728569, mean_eps: 0.100000\n",
            " 5406/10000: episode: 169, duration: 0.517s, episode steps:  56, steps per second: 108, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 4.943762, mae: 12.348261, mean_q: 23.969061, mean_eps: 0.100000\n",
            " 5485/10000: episode: 170, duration: 0.748s, episode steps:  79, steps per second: 106, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 4.869697, mae: 12.458663, mean_q: 24.109513, mean_eps: 0.100000\n",
            " 5548/10000: episode: 171, duration: 0.576s, episode steps:  63, steps per second: 109, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.540 [0.000, 1.000],  loss: 4.632277, mae: 12.557842, mean_q: 24.382340, mean_eps: 0.100000\n",
            " 5647/10000: episode: 172, duration: 0.886s, episode steps:  99, steps per second: 112, episode reward: 99.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 3.943662, mae: 12.746550, mean_q: 24.825830, mean_eps: 0.100000\n",
            " 5748/10000: episode: 173, duration: 0.920s, episode steps: 101, steps per second: 110, episode reward: 101.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 3.955563, mae: 13.019112, mean_q: 25.394805, mean_eps: 0.100000\n",
            " 5886/10000: episode: 174, duration: 1.241s, episode steps: 138, steps per second: 111, episode reward: 138.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 4.844130, mae: 13.213449, mean_q: 25.718255, mean_eps: 0.100000\n",
            " 5989/10000: episode: 175, duration: 1.273s, episode steps: 103, steps per second:  81, episode reward: 103.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 3.599482, mae: 13.404287, mean_q: 26.233537, mean_eps: 0.100000\n",
            " 6129/10000: episode: 176, duration: 1.684s, episode steps: 140, steps per second:  83, episode reward: 140.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 4.382015, mae: 13.618142, mean_q: 26.603647, mean_eps: 0.100000\n",
            " 6327/10000: episode: 177, duration: 1.798s, episode steps: 198, steps per second: 110, episode reward: 198.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 4.652212, mae: 14.000622, mean_q: 27.398405, mean_eps: 0.100000\n",
            " 6412/10000: episode: 178, duration: 0.772s, episode steps:  85, steps per second: 110, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 4.740929, mae: 14.239122, mean_q: 27.903501, mean_eps: 0.100000\n",
            " 6518/10000: episode: 179, duration: 1.010s, episode steps: 106, steps per second: 105, episode reward: 106.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 5.833897, mae: 14.442846, mean_q: 28.172059, mean_eps: 0.100000\n",
            " 6692/10000: episode: 180, duration: 1.607s, episode steps: 174, steps per second: 108, episode reward: 174.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 5.035517, mae: 14.647035, mean_q: 28.667084, mean_eps: 0.100000\n",
            " 6839/10000: episode: 181, duration: 1.362s, episode steps: 147, steps per second: 108, episode reward: 147.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 5.314290, mae: 14.906456, mean_q: 29.218067, mean_eps: 0.100000\n",
            " 7039/10000: episode: 182, duration: 1.840s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 4.956579, mae: 15.190600, mean_q: 29.857143, mean_eps: 0.100000\n",
            " 7211/10000: episode: 183, duration: 1.758s, episode steps: 172, steps per second:  98, episode reward: 172.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 5.234532, mae: 15.613943, mean_q: 30.731560, mean_eps: 0.100000\n",
            " 7396/10000: episode: 184, duration: 2.306s, episode steps: 185, steps per second:  80, episode reward: 185.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 5.873767, mae: 15.909064, mean_q: 31.313487, mean_eps: 0.100000\n",
            " 7553/10000: episode: 185, duration: 1.444s, episode steps: 157, steps per second: 109, episode reward: 157.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 5.041512, mae: 16.182626, mean_q: 31.953274, mean_eps: 0.100000\n",
            " 7753/10000: episode: 186, duration: 1.824s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 5.569420, mae: 16.421466, mean_q: 32.381343, mean_eps: 0.100000\n",
            " 7921/10000: episode: 187, duration: 1.542s, episode steps: 168, steps per second: 109, episode reward: 168.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 5.557504, mae: 16.653506, mean_q: 32.877587, mean_eps: 0.100000\n",
            " 8098/10000: episode: 188, duration: 1.655s, episode steps: 177, steps per second: 107, episode reward: 177.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 5.386988, mae: 16.890225, mean_q: 33.455252, mean_eps: 0.100000\n",
            " 8272/10000: episode: 189, duration: 1.601s, episode steps: 174, steps per second: 109, episode reward: 174.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 5.103282, mae: 17.135757, mean_q: 34.012797, mean_eps: 0.100000\n",
            " 8441/10000: episode: 190, duration: 1.610s, episode steps: 169, steps per second: 105, episode reward: 169.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 5.719436, mae: 17.366028, mean_q: 34.389082, mean_eps: 0.100000\n",
            " 8629/10000: episode: 191, duration: 2.465s, episode steps: 188, steps per second:  76, episode reward: 188.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 5.485017, mae: 17.672035, mean_q: 35.065744, mean_eps: 0.100000\n",
            " 8829/10000: episode: 192, duration: 1.836s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 5.314120, mae: 17.887325, mean_q: 35.516947, mean_eps: 0.100000\n",
            " 9029/10000: episode: 193, duration: 1.839s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 6.466749, mae: 18.139012, mean_q: 35.949698, mean_eps: 0.100000\n",
            " 9229/10000: episode: 194, duration: 1.821s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 5.670745, mae: 18.486432, mean_q: 36.736212, mean_eps: 0.100000\n",
            " 9429/10000: episode: 195, duration: 1.819s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 7.054805, mae: 18.797771, mean_q: 37.320824, mean_eps: 0.100000\n",
            " 9629/10000: episode: 196, duration: 1.810s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 6.158516, mae: 18.982859, mean_q: 37.718488, mean_eps: 0.100000\n",
            " 9829/10000: episode: 197, duration: 2.261s, episode steps: 200, steps per second:  88, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 5.724733, mae: 19.180437, mean_q: 38.218364, mean_eps: 0.100000\n",
            "done, took 105.014 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce0a7fd790>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### value_min=.4 & learning_rate=.0002"
      ],
      "metadata": {
        "id": "7hknfgtRdn0n"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfac761c-7a6e-4750-925d-979c399d7f66",
        "id": "yFfbIOcA6J0H"
      },
      "source": [
        "memory = SequentialMemory(limit=10000, window_length=1)\n",
        "\n",
        "policy =  LinearAnnealedPolicy(inner_policy=EpsGreedyQPolicy(0.2), \n",
        "                               attr='eps',            \n",
        "                               value_max=1.,\n",
        "                               value_min=.4, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=200)\n",
        "\n",
        "# Q-Network\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "# add extra layers here\n",
        "model.add(Flatten())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "print(model.summary())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_8 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 16)                80        \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 386\n",
            "Trainable params: 386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=10, # how many steps are waited before starting experience replay,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy) \n",
        "\n",
        "dqn.compile(Adam(learning_rate=.0002), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=1000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7fc5a5b2-2a98-41f6-9e0a-dcaa353801a5",
        "id": "LIC1o-ka6J0I"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 1000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 10 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 11 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 12 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 13 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 14 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 15 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 16 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 17 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 18 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 19 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 20 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 21 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 22 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 23 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 24 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 25 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 26 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 27 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 28 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 29 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 30 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n",
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 31 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  31/1000: episode: 1, duration: 2.738s, episode steps:  31, steps per second:  11, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.613 [0.000, 1.000],  loss: 0.520276, mae: 0.537390, mean_q: -0.024490, mean_eps: 0.938500\n",
            "  50/1000: episode: 2, duration: 0.118s, episode steps:  19, steps per second: 161, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.632 [0.000, 1.000],  loss: 0.506533, mae: 0.549730, mean_q: -0.045345, mean_eps: 0.880000\n",
            "  87/1000: episode: 3, duration: 0.211s, episode steps:  37, steps per second: 175, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 0.472664, mae: 0.517763, mean_q: 0.018000, mean_eps: 0.796000\n",
            " 109/1000: episode: 4, duration: 0.131s, episode steps:  22, steps per second: 168, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.318 [0.000, 1.000],  loss: 0.452102, mae: 0.509415, mean_q: 0.082310, mean_eps: 0.707500\n",
            " 129/1000: episode: 5, duration: 0.121s, episode steps:  20, steps per second: 165, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.432821, mae: 0.510985, mean_q: 0.147969, mean_eps: 0.644500\n",
            " 145/1000: episode: 6, duration: 0.105s, episode steps:  16, steps per second: 152, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 0.412630, mae: 0.514310, mean_q: 0.194336, mean_eps: 0.590500\n",
            " 155/1000: episode: 7, duration: 0.061s, episode steps:  10, steps per second: 165, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.416190, mae: 0.531388, mean_q: 0.225915, mean_eps: 0.551500\n",
            " 164/1000: episode: 8, duration: 0.058s, episode steps:   9, steps per second: 156, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.111 [0.000, 1.000],  loss: 0.401067, mae: 0.536943, mean_q: 0.274425, mean_eps: 0.523000\n",
            " 182/1000: episode: 9, duration: 0.099s, episode steps:  18, steps per second: 181, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.392280, mae: 0.544007, mean_q: 0.319760, mean_eps: 0.482500\n",
            " 206/1000: episode: 10, duration: 0.151s, episode steps:  24, steps per second: 159, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 0.386046, mae: 0.553459, mean_q: 0.367720, mean_eps: 0.421375\n",
            " 219/1000: episode: 11, duration: 0.086s, episode steps:  13, steps per second: 151, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.154 [0.000, 1.000],  loss: 0.382238, mae: 0.575851, mean_q: 0.430545, mean_eps: 0.400000\n",
            " 230/1000: episode: 12, duration: 0.067s, episode steps:  11, steps per second: 165, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.091 [0.000, 1.000],  loss: 0.373660, mae: 0.573599, mean_q: 0.466955, mean_eps: 0.400000\n",
            " 251/1000: episode: 13, duration: 0.125s, episode steps:  21, steps per second: 167, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.366985, mae: 0.592188, mean_q: 0.541811, mean_eps: 0.400000\n",
            " 261/1000: episode: 14, duration: 0.065s, episode steps:  10, steps per second: 154, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.357941, mae: 0.613744, mean_q: 0.633092, mean_eps: 0.400000\n",
            " 274/1000: episode: 15, duration: 0.082s, episode steps:  13, steps per second: 159, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 0.365977, mae: 0.633131, mean_q: 0.668417, mean_eps: 0.400000\n",
            " 294/1000: episode: 16, duration: 0.118s, episode steps:  20, steps per second: 169, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 0.370412, mae: 0.659356, mean_q: 0.712076, mean_eps: 0.400000\n",
            " 315/1000: episode: 17, duration: 0.124s, episode steps:  21, steps per second: 169, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.286 [0.000, 1.000],  loss: 0.370506, mae: 0.683914, mean_q: 0.763988, mean_eps: 0.400000\n",
            " 330/1000: episode: 18, duration: 0.092s, episode steps:  15, steps per second: 162, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 0.357981, mae: 0.695693, mean_q: 0.876557, mean_eps: 0.400000\n",
            " 340/1000: episode: 19, duration: 0.062s, episode steps:  10, steps per second: 160, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 0.373508, mae: 0.745266, mean_q: 0.975481, mean_eps: 0.400000\n",
            " 351/1000: episode: 20, duration: 0.089s, episode steps:  11, steps per second: 124, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 0.350534, mae: 0.738991, mean_q: 1.008028, mean_eps: 0.400000\n",
            " 362/1000: episode: 21, duration: 0.071s, episode steps:  11, steps per second: 155, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 0.357512, mae: 0.757310, mean_q: 1.042793, mean_eps: 0.400000\n",
            " 372/1000: episode: 22, duration: 0.071s, episode steps:  10, steps per second: 141, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 0.365517, mae: 0.796533, mean_q: 1.152791, mean_eps: 0.400000\n",
            " 386/1000: episode: 23, duration: 0.081s, episode steps:  14, steps per second: 174, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 0.383824, mae: 0.803313, mean_q: 1.155110, mean_eps: 0.400000\n",
            " 398/1000: episode: 24, duration: 0.072s, episode steps:  12, steps per second: 167, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.167 [0.000, 1.000],  loss: 0.378818, mae: 0.835862, mean_q: 1.200230, mean_eps: 0.400000\n",
            " 408/1000: episode: 25, duration: 0.058s, episode steps:  10, steps per second: 173, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.370890, mae: 0.857562, mean_q: 1.329697, mean_eps: 0.400000\n",
            " 419/1000: episode: 26, duration: 0.060s, episode steps:  11, steps per second: 183, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.091 [0.000, 1.000],  loss: 0.384710, mae: 0.875686, mean_q: 1.343811, mean_eps: 0.400000\n",
            " 435/1000: episode: 27, duration: 0.100s, episode steps:  16, steps per second: 160, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 0.415732, mae: 0.919043, mean_q: 1.444208, mean_eps: 0.400000\n",
            " 444/1000: episode: 28, duration: 0.059s, episode steps:   9, steps per second: 153, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 0.404971, mae: 0.929458, mean_q: 1.457474, mean_eps: 0.400000\n",
            " 460/1000: episode: 29, duration: 0.093s, episode steps:  16, steps per second: 171, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 0.417446, mae: 0.975865, mean_q: 1.559335, mean_eps: 0.400000\n",
            " 473/1000: episode: 30, duration: 0.079s, episode steps:  13, steps per second: 164, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 0.405582, mae: 1.001702, mean_q: 1.650485, mean_eps: 0.400000\n",
            " 485/1000: episode: 31, duration: 0.079s, episode steps:  12, steps per second: 152, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 0.445486, mae: 1.074849, mean_q: 1.814840, mean_eps: 0.400000\n",
            " 494/1000: episode: 32, duration: 0.057s, episode steps:   9, steps per second: 157, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.111 [0.000, 1.000],  loss: 0.447566, mae: 1.087009, mean_q: 1.836256, mean_eps: 0.400000\n",
            " 504/1000: episode: 33, duration: 0.075s, episode steps:  10, steps per second: 134, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.427648, mae: 1.093892, mean_q: 1.862871, mean_eps: 0.400000\n",
            " 512/1000: episode: 34, duration: 0.051s, episode steps:   8, steps per second: 158, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 0.462521, mae: 1.138824, mean_q: 1.929062, mean_eps: 0.400000\n",
            " 522/1000: episode: 35, duration: 0.061s, episode steps:  10, steps per second: 163, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.443952, mae: 1.151829, mean_q: 1.994437, mean_eps: 0.400000\n",
            " 532/1000: episode: 36, duration: 0.071s, episode steps:  10, steps per second: 141, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.458724, mae: 1.195087, mean_q: 2.094204, mean_eps: 0.400000\n",
            " 544/1000: episode: 37, duration: 0.077s, episode steps:  12, steps per second: 155, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 0.539180, mae: 1.237529, mean_q: 2.115984, mean_eps: 0.400000\n",
            " 557/1000: episode: 38, duration: 0.088s, episode steps:  13, steps per second: 147, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.154 [0.000, 1.000],  loss: 0.502446, mae: 1.257521, mean_q: 2.212100, mean_eps: 0.400000\n",
            " 565/1000: episode: 39, duration: 0.052s, episode steps:   8, steps per second: 153, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 0.702001, mae: 1.363663, mean_q: 2.375910, mean_eps: 0.400000\n",
            " 575/1000: episode: 40, duration: 0.066s, episode steps:  10, steps per second: 152, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 0.525653, mae: 1.338562, mean_q: 2.340475, mean_eps: 0.400000\n",
            " 587/1000: episode: 41, duration: 0.072s, episode steps:  12, steps per second: 166, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 0.610984, mae: 1.369161, mean_q: 2.384081, mean_eps: 0.400000\n",
            " 602/1000: episode: 42, duration: 0.080s, episode steps:  15, steps per second: 187, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.267 [0.000, 1.000],  loss: 0.576616, mae: 1.417392, mean_q: 2.488825, mean_eps: 0.400000\n",
            " 614/1000: episode: 43, duration: 0.068s, episode steps:  12, steps per second: 177, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.167 [0.000, 1.000],  loss: 0.699041, mae: 1.478806, mean_q: 2.579227, mean_eps: 0.400000\n",
            " 632/1000: episode: 44, duration: 0.093s, episode steps:  18, steps per second: 194, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.620458, mae: 1.496191, mean_q: 2.673341, mean_eps: 0.400000\n",
            " 641/1000: episode: 45, duration: 0.050s, episode steps:   9, steps per second: 179, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 0.546821, mae: 1.437762, mean_q: 2.653385, mean_eps: 0.400000\n",
            " 650/1000: episode: 46, duration: 0.054s, episode steps:   9, steps per second: 168, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 0.749774, mae: 1.586959, mean_q: 2.842191, mean_eps: 0.400000\n",
            " 660/1000: episode: 47, duration: 0.072s, episode steps:  10, steps per second: 139, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.731714, mae: 1.625406, mean_q: 3.014259, mean_eps: 0.400000\n",
            " 672/1000: episode: 48, duration: 0.080s, episode steps:  12, steps per second: 150, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.167 [0.000, 1.000],  loss: 0.871605, mae: 1.631670, mean_q: 2.957376, mean_eps: 0.400000\n",
            " 682/1000: episode: 49, duration: 0.065s, episode steps:  10, steps per second: 153, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.873828, mae: 1.689978, mean_q: 2.996146, mean_eps: 0.400000\n",
            " 696/1000: episode: 50, duration: 0.103s, episode steps:  14, steps per second: 136, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.214 [0.000, 1.000],  loss: 0.788947, mae: 1.686929, mean_q: 3.059851, mean_eps: 0.400000\n",
            " 709/1000: episode: 51, duration: 0.081s, episode steps:  13, steps per second: 160, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 1.037030, mae: 1.787098, mean_q: 3.074399, mean_eps: 0.400000\n",
            " 719/1000: episode: 52, duration: 0.067s, episode steps:  10, steps per second: 148, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.889341, mae: 1.758763, mean_q: 3.083980, mean_eps: 0.400000\n",
            " 729/1000: episode: 53, duration: 0.066s, episode steps:  10, steps per second: 152, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.788913, mae: 1.740040, mean_q: 3.134026, mean_eps: 0.400000\n",
            " 739/1000: episode: 54, duration: 0.063s, episode steps:  10, steps per second: 160, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.890851, mae: 1.844569, mean_q: 3.310569, mean_eps: 0.400000\n",
            " 765/1000: episode: 55, duration: 0.149s, episode steps:  26, steps per second: 175, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.385 [0.000, 1.000],  loss: 0.961020, mae: 1.876475, mean_q: 3.411643, mean_eps: 0.400000\n",
            " 779/1000: episode: 56, duration: 0.079s, episode steps:  14, steps per second: 177, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.214 [0.000, 1.000],  loss: 1.036251, mae: 1.961485, mean_q: 3.494324, mean_eps: 0.400000\n",
            " 792/1000: episode: 57, duration: 0.078s, episode steps:  13, steps per second: 167, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.231 [0.000, 1.000],  loss: 1.048857, mae: 2.003790, mean_q: 3.634070, mean_eps: 0.400000\n",
            " 802/1000: episode: 58, duration: 0.070s, episode steps:  10, steps per second: 142, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 1.225534, mae: 2.061545, mean_q: 3.644687, mean_eps: 0.400000\n",
            " 814/1000: episode: 59, duration: 0.076s, episode steps:  12, steps per second: 158, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.167 [0.000, 1.000],  loss: 0.985030, mae: 2.023198, mean_q: 3.592086, mean_eps: 0.400000\n",
            " 826/1000: episode: 60, duration: 0.075s, episode steps:  12, steps per second: 160, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 1.055895, mae: 2.080966, mean_q: 3.772544, mean_eps: 0.400000\n",
            " 839/1000: episode: 61, duration: 0.086s, episode steps:  13, steps per second: 151, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 1.032340, mae: 2.132738, mean_q: 3.873269, mean_eps: 0.400000\n",
            " 852/1000: episode: 62, duration: 0.084s, episode steps:  13, steps per second: 155, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.231 [0.000, 1.000],  loss: 1.224501, mae: 2.223869, mean_q: 3.993343, mean_eps: 0.400000\n",
            " 862/1000: episode: 63, duration: 0.069s, episode steps:  10, steps per second: 146, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 1.367052, mae: 2.265496, mean_q: 3.984593, mean_eps: 0.400000\n",
            " 872/1000: episode: 64, duration: 0.074s, episode steps:  10, steps per second: 136, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 1.256464, mae: 2.257424, mean_q: 4.066772, mean_eps: 0.400000\n",
            " 885/1000: episode: 65, duration: 0.081s, episode steps:  13, steps per second: 160, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.154 [0.000, 1.000],  loss: 0.991037, mae: 2.208777, mean_q: 4.060070, mean_eps: 0.400000\n",
            " 899/1000: episode: 66, duration: 0.089s, episode steps:  14, steps per second: 156, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.214 [0.000, 1.000],  loss: 1.543993, mae: 2.357294, mean_q: 4.184721, mean_eps: 0.400000\n",
            " 909/1000: episode: 67, duration: 0.066s, episode steps:  10, steps per second: 151, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.911927, mae: 2.197104, mean_q: 4.082042, mean_eps: 0.400000\n",
            " 924/1000: episode: 68, duration: 0.091s, episode steps:  15, steps per second: 164, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 1.240820, mae: 2.364888, mean_q: 4.283570, mean_eps: 0.400000\n",
            " 937/1000: episode: 69, duration: 0.083s, episode steps:  13, steps per second: 157, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.231 [0.000, 1.000],  loss: 1.246074, mae: 2.347294, mean_q: 4.329601, mean_eps: 0.400000\n",
            " 954/1000: episode: 70, duration: 0.110s, episode steps:  17, steps per second: 154, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.294 [0.000, 1.000],  loss: 1.133424, mae: 2.397543, mean_q: 4.441757, mean_eps: 0.400000\n",
            " 970/1000: episode: 71, duration: 0.103s, episode steps:  16, steps per second: 156, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.188 [0.000, 1.000],  loss: 1.265656, mae: 2.471955, mean_q: 4.613019, mean_eps: 0.400000\n",
            " 979/1000: episode: 72, duration: 0.057s, episode steps:   9, steps per second: 158, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.111 [0.000, 1.000],  loss: 1.157320, mae: 2.459779, mean_q: 4.637633, mean_eps: 0.400000\n",
            " 989/1000: episode: 73, duration: 0.066s, episode steps:  10, steps per second: 151, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.300 [0.000, 1.000],  loss: 1.127394, mae: 2.516426, mean_q: 4.728856, mean_eps: 0.400000\n",
            "done, took 8.837 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 9.000, steps: 9\n",
            "Episode 2: reward: 10.000, steps: 10\n",
            "Episode 3: reward: 10.000, steps: 10\n",
            "Episode 4: reward: 10.000, steps: 10\n",
            "Episode 5: reward: 9.000, steps: 9\n",
            "Episode 6: reward: 9.000, steps: 9\n",
            "Episode 7: reward: 9.000, steps: 9\n",
            "Episode 8: reward: 9.000, steps: 9\n",
            "Episode 9: reward: 10.000, steps: 10\n",
            "Episode 10: reward: 9.000, steps: 9\n",
            "Episode 11: reward: 8.000, steps: 8\n",
            "Episode 12: reward: 9.000, steps: 9\n",
            "Episode 13: reward: 9.000, steps: 9\n",
            "Episode 14: reward: 9.000, steps: 9\n",
            "Episode 15: reward: 10.000, steps: 10\n",
            "Episode 16: reward: 10.000, steps: 10\n",
            "Episode 17: reward: 10.000, steps: 10\n",
            "Episode 18: reward: 11.000, steps: 11\n",
            "Episode 19: reward: 9.000, steps: 9\n",
            "Episode 20: reward: 10.000, steps: 10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f60abec2be0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZK9xCfIu6S0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Warm up 50 & gamma 0.99"
      ],
      "metadata": {
        "id": "TwLlwJ4elI0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = SequentialMemory(limit=10000, window_length=1)\n",
        "\n",
        "policy =  LinearAnnealedPolicy(inner_policy=EpsGreedyQPolicy(0.2), \n",
        "                               attr='eps',            \n",
        "                               value_max=1.,\n",
        "                               value_min=.1, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=200)\n",
        "\n",
        "# Q-Network\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "# add extra layers here\n",
        "model.add(Flatten())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTTi6eWJD6Sg",
        "outputId": "d90f0345-6a8f-4c33-984f-e096f27f7857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 16)                80        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 386\n",
            "Trainable params: 386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=50, # how many steps are waited before starting experience replay,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy,\n",
        "               gamma=0.99) \n",
        "\n",
        "dqn.compile(Adam(learning_rate=.0003), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DXbO6Slo7Pr8",
        "outputId": "0a22241e-a868-4bf1-9914-bf4b86e6fa0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n",
            "   15/10000: episode: 1, duration: 0.115s, episode steps:  15, steps per second: 131, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  160/10000: episode: 2, duration: 1.369s, episode steps: 145, steps per second: 106, episode reward: 145.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 5.312000, mae: 17.300948, mean_q: 34.461483, mean_eps: 0.527500\n",
            "  267/10000: episode: 3, duration: 0.684s, episode steps: 107, steps per second: 157, episode reward: 107.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 5.799226, mae: 16.570299, mean_q: 33.004069, mean_eps: 0.134486\n",
            "  366/10000: episode: 4, duration: 0.611s, episode steps:  99, steps per second: 162, episode reward: 99.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 3.608364, mae: 16.228690, mean_q: 32.365204, mean_eps: 0.100000\n",
            "  460/10000: episode: 5, duration: 0.631s, episode steps:  94, steps per second: 149, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 2.904772, mae: 16.125915, mean_q: 32.148143, mean_eps: 0.100000\n",
            "  556/10000: episode: 6, duration: 0.736s, episode steps:  96, steps per second: 130, episode reward: 96.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 1.466384, mae: 16.157590, mean_q: 32.334814, mean_eps: 0.100000\n",
            "  642/10000: episode: 7, duration: 0.782s, episode steps:  86, steps per second: 110, episode reward: 86.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.453 [0.000, 1.000],  loss: 2.251842, mae: 16.131575, mean_q: 32.195111, mean_eps: 0.100000\n",
            "  735/10000: episode: 8, duration: 0.863s, episode steps:  93, steps per second: 108, episode reward: 93.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 1.913938, mae: 16.278437, mean_q: 32.495066, mean_eps: 0.100000\n",
            "  832/10000: episode: 9, duration: 0.833s, episode steps:  97, steps per second: 116, episode reward: 97.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.464 [0.000, 1.000],  loss: 1.625160, mae: 16.449111, mean_q: 32.903320, mean_eps: 0.100000\n",
            "  956/10000: episode: 10, duration: 0.798s, episode steps: 124, steps per second: 155, episode reward: 124.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 1.537818, mae: 16.836125, mean_q: 33.679642, mean_eps: 0.100000\n",
            " 1043/10000: episode: 11, duration: 0.557s, episode steps:  87, steps per second: 156, episode reward: 87.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 1.635793, mae: 17.046545, mean_q: 34.075025, mean_eps: 0.100000\n",
            " 1129/10000: episode: 12, duration: 0.558s, episode steps:  86, steps per second: 154, episode reward: 86.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.453 [0.000, 1.000],  loss: 1.548988, mae: 16.958209, mean_q: 33.891036, mean_eps: 0.100000\n",
            " 1226/10000: episode: 13, duration: 0.625s, episode steps:  97, steps per second: 155, episode reward: 97.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 0.974050, mae: 17.187731, mean_q: 34.445799, mean_eps: 0.100000\n",
            " 1324/10000: episode: 14, duration: 0.611s, episode steps:  98, steps per second: 160, episode reward: 98.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 1.502863, mae: 17.202153, mean_q: 34.486345, mean_eps: 0.100000\n",
            " 1431/10000: episode: 15, duration: 0.692s, episode steps: 107, steps per second: 155, episode reward: 107.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 1.128220, mae: 17.400485, mean_q: 34.908983, mean_eps: 0.100000\n",
            " 1552/10000: episode: 16, duration: 0.765s, episode steps: 121, steps per second: 158, episode reward: 121.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 1.205612, mae: 17.481361, mean_q: 35.050644, mean_eps: 0.100000\n",
            " 1666/10000: episode: 17, duration: 0.709s, episode steps: 114, steps per second: 161, episode reward: 114.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 1.480144, mae: 17.656183, mean_q: 35.414453, mean_eps: 0.100000\n",
            " 1800/10000: episode: 18, duration: 0.851s, episode steps: 134, steps per second: 157, episode reward: 134.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 1.086612, mae: 17.773356, mean_q: 35.703121, mean_eps: 0.100000\n",
            " 1935/10000: episode: 19, duration: 0.851s, episode steps: 135, steps per second: 159, episode reward: 135.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 0.558691, mae: 18.060169, mean_q: 36.326811, mean_eps: 0.100000\n",
            " 2069/10000: episode: 20, duration: 0.884s, episode steps: 134, steps per second: 152, episode reward: 134.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 0.981192, mae: 18.332575, mean_q: 36.931737, mean_eps: 0.100000\n",
            " 2203/10000: episode: 21, duration: 0.858s, episode steps: 134, steps per second: 156, episode reward: 134.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 1.395167, mae: 18.649835, mean_q: 37.531156, mean_eps: 0.100000\n",
            " 2309/10000: episode: 22, duration: 0.657s, episode steps: 106, steps per second: 161, episode reward: 106.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 0.883176, mae: 18.624844, mean_q: 37.493627, mean_eps: 0.100000\n",
            " 2423/10000: episode: 23, duration: 0.889s, episode steps: 114, steps per second: 128, episode reward: 114.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 0.689354, mae: 18.823900, mean_q: 37.887261, mean_eps: 0.100000\n",
            " 2534/10000: episode: 24, duration: 1.017s, episode steps: 111, steps per second: 109, episode reward: 111.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 0.663327, mae: 18.889744, mean_q: 38.068794, mean_eps: 0.100000\n",
            " 2657/10000: episode: 25, duration: 1.138s, episode steps: 123, steps per second: 108, episode reward: 123.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 0.912341, mae: 19.018358, mean_q: 38.333935, mean_eps: 0.100000\n",
            " 2798/10000: episode: 26, duration: 0.886s, episode steps: 141, steps per second: 159, episode reward: 141.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 0.668111, mae: 19.240034, mean_q: 38.791212, mean_eps: 0.100000\n",
            " 2948/10000: episode: 27, duration: 0.947s, episode steps: 150, steps per second: 158, episode reward: 150.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 1.073087, mae: 19.343680, mean_q: 38.984997, mean_eps: 0.100000\n",
            " 3049/10000: episode: 28, duration: 0.641s, episode steps: 101, steps per second: 157, episode reward: 101.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 0.630740, mae: 19.401127, mean_q: 39.092099, mean_eps: 0.100000\n",
            " 3187/10000: episode: 29, duration: 0.847s, episode steps: 138, steps per second: 163, episode reward: 138.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 0.704353, mae: 19.684315, mean_q: 39.646950, mean_eps: 0.100000\n",
            " 3304/10000: episode: 30, duration: 0.735s, episode steps: 117, steps per second: 159, episode reward: 117.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 0.764316, mae: 19.853952, mean_q: 39.994042, mean_eps: 0.100000\n",
            " 3446/10000: episode: 31, duration: 0.882s, episode steps: 142, steps per second: 161, episode reward: 142.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 0.807214, mae: 20.108706, mean_q: 40.496095, mean_eps: 0.100000\n",
            " 3584/10000: episode: 32, duration: 0.849s, episode steps: 138, steps per second: 162, episode reward: 138.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 1.532830, mae: 20.152766, mean_q: 40.537953, mean_eps: 0.100000\n",
            " 3704/10000: episode: 33, duration: 0.742s, episode steps: 120, steps per second: 162, episode reward: 120.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 0.349204, mae: 20.132399, mean_q: 40.519543, mean_eps: 0.100000\n",
            " 3836/10000: episode: 34, duration: 0.793s, episode steps: 132, steps per second: 166, episode reward: 132.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 0.188828, mae: 20.422185, mean_q: 41.129572, mean_eps: 0.100000\n",
            " 3953/10000: episode: 35, duration: 0.735s, episode steps: 117, steps per second: 159, episode reward: 117.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 1.006042, mae: 20.481287, mean_q: 41.207061, mean_eps: 0.100000\n",
            " 4071/10000: episode: 36, duration: 0.735s, episode steps: 118, steps per second: 161, episode reward: 118.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 0.732664, mae: 20.585662, mean_q: 41.391230, mean_eps: 0.100000\n",
            " 4200/10000: episode: 37, duration: 0.802s, episode steps: 129, steps per second: 161, episode reward: 129.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 0.179547, mae: 20.668103, mean_q: 41.589070, mean_eps: 0.100000\n",
            " 4313/10000: episode: 38, duration: 0.851s, episode steps: 113, steps per second: 133, episode reward: 113.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 1.064605, mae: 20.702272, mean_q: 41.590456, mean_eps: 0.100000\n",
            " 4449/10000: episode: 39, duration: 1.209s, episode steps: 136, steps per second: 112, episode reward: 136.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 0.655626, mae: 20.822684, mean_q: 41.855146, mean_eps: 0.100000\n",
            " 4584/10000: episode: 40, duration: 1.119s, episode steps: 135, steps per second: 121, episode reward: 135.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 0.314315, mae: 21.200526, mean_q: 42.622306, mean_eps: 0.100000\n",
            " 4703/10000: episode: 41, duration: 0.742s, episode steps: 119, steps per second: 160, episode reward: 119.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 0.152217, mae: 21.056285, mean_q: 42.323100, mean_eps: 0.100000\n",
            " 4820/10000: episode: 42, duration: 0.739s, episode steps: 117, steps per second: 158, episode reward: 117.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 0.941920, mae: 21.215479, mean_q: 42.654266, mean_eps: 0.100000\n",
            " 4951/10000: episode: 43, duration: 0.816s, episode steps: 131, steps per second: 161, episode reward: 131.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 0.548462, mae: 21.323437, mean_q: 42.857256, mean_eps: 0.100000\n",
            " 5103/10000: episode: 44, duration: 0.974s, episode steps: 152, steps per second: 156, episode reward: 152.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 0.173892, mae: 21.412726, mean_q: 43.050992, mean_eps: 0.100000\n",
            " 5250/10000: episode: 45, duration: 0.925s, episode steps: 147, steps per second: 159, episode reward: 147.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 0.138068, mae: 21.700413, mean_q: 43.674909, mean_eps: 0.100000\n",
            " 5432/10000: episode: 46, duration: 1.131s, episode steps: 182, steps per second: 161, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 0.670976, mae: 21.806421, mean_q: 43.848258, mean_eps: 0.100000\n",
            " 5615/10000: episode: 47, duration: 1.120s, episode steps: 183, steps per second: 163, episode reward: 183.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 0.646650, mae: 21.947503, mean_q: 44.131702, mean_eps: 0.100000\n",
            " 5771/10000: episode: 48, duration: 0.959s, episode steps: 156, steps per second: 163, episode reward: 156.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 0.316366, mae: 22.196824, mean_q: 44.653480, mean_eps: 0.100000\n",
            " 5923/10000: episode: 49, duration: 0.952s, episode steps: 152, steps per second: 160, episode reward: 152.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 0.378989, mae: 22.437600, mean_q: 45.135400, mean_eps: 0.100000\n",
            " 6065/10000: episode: 50, duration: 0.920s, episode steps: 142, steps per second: 154, episode reward: 142.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 0.122959, mae: 22.831935, mean_q: 45.966641, mean_eps: 0.100000\n",
            " 6206/10000: episode: 51, duration: 1.143s, episode steps: 141, steps per second: 123, episode reward: 141.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 0.401571, mae: 22.614731, mean_q: 45.513703, mean_eps: 0.100000\n",
            " 6376/10000: episode: 52, duration: 1.531s, episode steps: 170, steps per second: 111, episode reward: 170.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 0.484917, mae: 22.830378, mean_q: 45.921879, mean_eps: 0.100000\n",
            " 6539/10000: episode: 53, duration: 1.178s, episode steps: 163, steps per second: 138, episode reward: 163.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 0.310747, mae: 23.053018, mean_q: 46.398915, mean_eps: 0.100000\n",
            " 6709/10000: episode: 54, duration: 1.080s, episode steps: 170, steps per second: 157, episode reward: 170.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 0.297638, mae: 23.151038, mean_q: 46.608588, mean_eps: 0.100000\n",
            " 6909/10000: episode: 55, duration: 1.260s, episode steps: 200, steps per second: 159, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 0.502821, mae: 23.028095, mean_q: 46.326134, mean_eps: 0.100000\n",
            " 7057/10000: episode: 56, duration: 0.976s, episode steps: 148, steps per second: 152, episode reward: 148.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 0.137463, mae: 23.598894, mean_q: 47.505537, mean_eps: 0.100000\n",
            " 7239/10000: episode: 57, duration: 1.156s, episode steps: 182, steps per second: 157, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 0.118537, mae: 23.878283, mean_q: 48.074457, mean_eps: 0.100000\n",
            " 7385/10000: episode: 58, duration: 0.922s, episode steps: 146, steps per second: 158, episode reward: 146.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 1.003488, mae: 24.146234, mean_q: 48.543968, mean_eps: 0.100000\n",
            " 7564/10000: episode: 59, duration: 1.120s, episode steps: 179, steps per second: 160, episode reward: 179.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 0.141937, mae: 24.081459, mean_q: 48.431874, mean_eps: 0.100000\n",
            " 7733/10000: episode: 60, duration: 1.072s, episode steps: 169, steps per second: 158, episode reward: 169.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 0.317466, mae: 24.246483, mean_q: 48.784094, mean_eps: 0.100000\n",
            " 7914/10000: episode: 61, duration: 1.180s, episode steps: 181, steps per second: 153, episode reward: 181.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 0.136738, mae: 24.176133, mean_q: 48.647528, mean_eps: 0.100000\n",
            " 8078/10000: episode: 62, duration: 1.305s, episode steps: 164, steps per second: 126, episode reward: 164.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 0.641798, mae: 24.367875, mean_q: 49.001536, mean_eps: 0.100000\n",
            " 8240/10000: episode: 63, duration: 1.499s, episode steps: 162, steps per second: 108, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 0.633744, mae: 24.832643, mean_q: 49.924913, mean_eps: 0.100000\n",
            " 8440/10000: episode: 64, duration: 1.368s, episode steps: 200, steps per second: 146, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 0.107881, mae: 24.663099, mean_q: 49.608973, mean_eps: 0.100000\n",
            " 8602/10000: episode: 65, duration: 1.017s, episode steps: 162, steps per second: 159, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 0.769191, mae: 24.818532, mean_q: 49.908983, mean_eps: 0.100000\n",
            " 8779/10000: episode: 66, duration: 1.135s, episode steps: 177, steps per second: 156, episode reward: 177.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 0.331158, mae: 25.124194, mean_q: 50.550841, mean_eps: 0.100000\n",
            " 8967/10000: episode: 67, duration: 1.178s, episode steps: 188, steps per second: 160, episode reward: 188.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 0.601286, mae: 25.037837, mean_q: 50.351098, mean_eps: 0.100000\n",
            " 9137/10000: episode: 68, duration: 1.089s, episode steps: 170, steps per second: 156, episode reward: 170.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 0.330641, mae: 25.017378, mean_q: 50.286725, mean_eps: 0.100000\n",
            " 9337/10000: episode: 69, duration: 1.303s, episode steps: 200, steps per second: 153, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 0.753832, mae: 25.378332, mean_q: 51.026265, mean_eps: 0.100000\n",
            " 9537/10000: episode: 70, duration: 1.325s, episode steps: 200, steps per second: 151, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 0.426268, mae: 25.338951, mean_q: 50.916123, mean_eps: 0.100000\n",
            " 9737/10000: episode: 71, duration: 1.315s, episode steps: 200, steps per second: 152, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 0.204291, mae: 25.417773, mean_q: 51.095835, mean_eps: 0.100000\n",
            " 9932/10000: episode: 72, duration: 1.601s, episode steps: 195, steps per second: 122, episode reward: 195.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 0.429635, mae: 25.559243, mean_q: 51.369966, mean_eps: 0.100000\n",
            "done, took 68.635 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEGCAYAAABhMDI9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABFS0lEQVR4nO3deXyc1XX4/8/Rvu+yLFuWN8xmvGCMMWEJCYQtaUhoNkJSsjQkLUnTLc3Sln7bpmnSLUn7a0hIICEp0DQJBAIEAgSzBQxewBs2XiVbi7Xv0kijOb8/nucZzWhGy0gzmrF13q+XXpp5nlmuJPs5c++591xRVYwxxhhPWrIbYIwxJrVYYDDGGBPGAoMxxpgwFhiMMcaEscBgjDEmTEayGzBbFRUVumzZsmQ3wxhjTinbt29vU9XKaOdO+cCwbNkytm3bluxmGGPMKUVE6iY6Z0NJxhhjwlhgMMYYE8YCgzHGmDAWGIwxxoSxwGCMMSZMQgODiCwRkWdEZJ+I7BWRz7vHy0TkSRE56H4vdY+LiPyniBwSkV0isiGR7TPGGBMp0T0GP/AXqnousBm4TUTOBb4EPK2qq4Cn3fsA1wGr3K9bgTsS3D5jjDHjJHQdg6o2AU3u7V4ReQNYDNwAXOE+7B5gC/BF9/iP1akF/rKIlIhItfs6xph54tVjHeRnZXDuoqJkNyXMaED5+fbj3Lihhsz0+H2u/t2hNl4+0j7pY/KzM7h581IKshO//GzOFriJyDLgfGArUBVysW8Gqtzbi4HjIU874R4LCwwicitOj4La2trENdoYkxRf/Pkullfkc9fHLkx2U8JsPdLOF3+xm8rCbN5+dtXUT5im2x/ey6GWPkQmfowqbKvr5HsfuYC0tEkeGAdzEhhEpAD4BfCnqtojIT+9qqqIxLRbkKreCdwJsHHjRttpyJjTyGhAqe8YoDA3M9lNidDYPeR87xqK22sG3J/305ev4MvXnzPh43744lH+/lf7+K/fHuLzV62K2/tHk/BZSSKSiRMU7lXVB9zDJ0Wk2j1fDbS4xxuAJSFPr3GPGWPmiabuQfwBpWtgONlNiXCyZyjsezy09PoY9gdYUpY36eM+9pZl/P6GGr751Js8ue9k3N4/mkTPShLgLuANVf2PkFMPA7e4t28BHgo5/gfu7KTNQLflF4yZX+rbBwDo6E+9wNDs9hi87/FQ194PQO0UgUFE+Kf3nsfammL+7KevcailL25tGC/RPYZLgI8CbxeR19yv64GvA+8QkYPAVe59gMeAI8Ah4PvAHye4fcaYFFPf4QSG3iE/I6OBJLcmXLPbU2iOY4/B+3mnCgwAOZnpfPcjF5CTmcatP95Gz9BI3NoRKtGzkl4AJsqSXBnl8Qrclsg2GWNSm3ehBOgcGGZBYU4SWxMuEUNJxzsGSBNYXJo7rccvKsnlOzdfwIe//zJffWQf//K+dXFri+eUL7ttjDm9hAaGroGRlAoMiRhKqu8YYFFJbkzTXzctL+O/bjqfDUtL49aOUBYYjDEppb5jgOyMNHz+QErlGfyjAdr6fORkptEz5GdweJTcrPRZv25dx8C0hpHGu25N9azfeyJWK8kYk1LqOwY4b3ExAJ0pFBha+3wEFM5b5LQtXnmG4zMMDIlkgcEYkzK6B0foGhhhXU0JAB0pNGXVGz5at6Qk7P5s9Pv8tPUNU1tugcEYY6I67uYX1i1xPpV3DSRm1s1MeAlnLzDEIwF9vHP6M5LmkgUGY0zK8BLPZywoID8rPaVyDE1uD2G925uJx1BSXbsFBmOMmZQXGJaU5VGan5VSOYbmniEy04Wa0lwKsjOmPZR0vGOAv//VXob9kWsyjsewhmEuWWAwxqSM+o4BSvMyKcrJpCw/K6VyDCe7h1hQmENamlBVlD3toaTvP3+EH754jJ31nRHn6jsGKMrJoCQvK97NnRULDMaYlHG8Y4Da8nwASvOy6EyhHENzzxALi501FQuLc6Y1lDTsD/Dw640A7Kjvijhf3zGQcolnsMBgjEkhde1jUzdL8zJTaijpZI+PhUVOYKgqyuHkNIaSthxooWtghIw0YUe0HkN76k1VBQsMxpgU4R8N0NA1SG2ZUxoilXIMqkpz9xBVbmBYWJRDS6+PQGDyqv8P7GigoiCbd66tZmd9J07VH8doQDnROThlVdVksMBgjAGgrc/H8wdb8flHk/L+Td1DjAY0+Am6LC+LXp8/atJ2rvUM+RkcGaU6ZCjJH1Da+n0TPqd7YITf7m/h3esWceGyMtr6hjneMRg8f7JniOHRQEr2GKwkhjHz1MhogCf3neSlw+28fKSdg24Z56/fuIYPbZr7nRFDZySB02MA6BqMXkjvUEsfZywomJO2eYnmquKxoSSAk92+CWs5PbK7keHRADduWEyauznZjvrOYE7B+3mXluUntO0zYT0GY+apB3c28Mf37uCBHSdYVJLLF689m7ysdN48mbg6/5Px5vQvDUk+A3T2RyagXz/exVX/8Szb6zpm9Z4tPUNTDgfB2CrnhSFDSTD5WoYHdjRwZlUBqxcVcdbCQvKz0tleN5ZnqE/RNQxggcGYeauuvZ/0NGHn7Vdzzyc28UdXrGR5RT5H25ITGOo7BshMl+BFtzTf2doz2iI3b5Oaw639M36/E50DXPqNZ/j59hNTPtYLAMHAUDx5YKhr72d7XSfvPb8GESE9TVi3pCQsAV3fMUB6mlBdkjrVYz0WGIyZpxq7hlhYlENWxthlwAkMM7/YzsbxjgFqSvNIdze6L3OHkjqjrGVo7HLG6pum2Ht5st7Ao7uaGB4N8Pyhtinb5s1AWlCUDUBFQTbpaTLhzKQHdjQgAu85f1Hw2IbaUvY39zIw7Ae8cts5MZXbniup1yJjzJxo7BoMJlM9KyryOd45mJSEb33HQNgMnbK8iQNDgxsYmnsGI855/vGRfXzgey+FzQQK9dhuZ9fgV492TPgYT3PPEKV5meRkOmW209OEyoLsqD0GVeXBnQ28ZWU51cVjm+9sWFrCaEB5/Xh38OdNxfwCWGAwZt5q6h5iUUn4rmHLK/MZDWjYZjlzpa69n6UhgaEkmGOYODA0TtJj2Fnfyba6zqgLy453DPD6iW6WlefR3DPEic6JAww4yWcv4eypKs6Juvp5e10n9R0DvPf8mrDj5y9xNtXxhpPGB8JUktDAICJ3i0iLiOwJOfbTkP2fj4nIa+7xZSIyGHLuu4lsmzHzWSCgNHUPRoxvL69wZvnM9XBS98AIPUP+sERsVkYaBdkZdERJPntDSZPVK/KCx/2v1Eec83oLX7n+HAC2TZHEDl317FlYlB31/X/5WgM5mWlce97CsOOl+VmsqMxnZ30nvUMjdPQPp2TiGRLfY/gRcG3oAVX9oKquV9X1wC+AB0JOH/bOqepnEtw2Y+attn4fI6PKouJxPQZ3RtBcJ6DHT1X1lOZnRgwlqWqwp9DYHf2Tvs8/Skuvj6z0NB7Z1Uj3YHhweXR3E2trirnynCoKczJ45WjkquRQzd1jq549C4siy2KoKlsOtHLZqkoKsiNXA2yoLWVHfVfw552XgUFVnwOihmIREeADwP2JbIMxJpKXtB0/lFScl0l5ftac9xgmulCW5WVFBIaugREGR0apLMymd8hPn88f8XpNXUOowocvqmVoJMCDO8ZmHh3vGGDXiW7euaaa9DRh49JSth2buMcwMhqgvd8XdSipd8gfTCZ7P8eJzkEuW1UR9bU21JbS0T/MCwfbov68qSKZOYbLgJOqejDk2HIR2Skiz4rIZRM9UURuFZFtIrKttbU18S015jTjDcWMTz6DMzPpyCymgc5EXYfzfuMLypXkRZbF8IaINi51xuybo/QavMdcvbqKtTXF3PdKfTDB/Kg7jHS9u2fyxmVlHGzpm7D8RkuvD1WiDCW5U1ZDhpOedy/4l5wxQWBYWgLAL19rjPrzpopkBoabCO8tNAG1qno+8OfAfSJSFO2Jqnqnqm5U1Y2VlZVz0FRjTi+N3dF7DJCcKavHOwYoz8+KGH6JVnrbu+hf4AaGaAnoBjeZXFOSx4c31fLmyb5g0vex3U2sqykODltduKwMgG110YeTxi9u80Rb5PbioTYWFeewoiL6bKNVCwopyM7gjaYeinMzKc7NjPq4ZEtKYBCRDOBG4KfeMVX1qWq7e3s7cBg4MxntM+Z019Q1SE5mGqV5kRem5ZX5tPT6og7RJMpEM3RK87IiVj57vZ2N7gU9WgL4RNcgIs6n/N9bt4iC7Azu3VpPfbs7jLS2OvjYtTXFZKWnTTicFCyHEWUoKfT8aED53eF2LjmjAnFLYIyXniasd7cGTdVhJEhej+EqYL+qBgf+RKRSRNLd2yuAVcCRJLXPmNNaY/cgi4pzo17AvE+7x+aw11DfEb38dFl+Jn3jCuk1ukHtnOpC5360oaTOQaoKncV7+dkZ3LB+EY/uauI+d4bSdeeNBYaczHTW1hTzygSBIdhjmHAoySmkt6ehm+7BES6dIL/g2VBbAszjwCAi9wMvAWeJyAkR+aR76kNEJp0vB3a501d/DnxGVWdXCMUYE1VjV+QaBo83ZfVInALDoZa+SWsajYwGaOwaYmmU8XZvLUNXyHBSQ9cgi0pyyc5Ip6IgK2qPoaFrgMWlYz/fhy+qxecPcOdzh1m3pCSid3Lh8jL2NHQzOBxZWfZkzxBZGZG9q/zsDAqzM4I9hhcOTZ5f8JzvDoGlan4BEj8r6SZVrVbVTFWtUdW73OMfU9XvjnvsL1R1tTtVdYOq/iqRbTNmPmvqjlz17FlanocIHI1TAvprj73BR+96ZcKtMH+z9ySjAeXshZEpRa8sRkdYYBhisRvUqotzg/mSUA1dg9SEBIbVi4pZt6SEgMK71lRHPP7CZaWMjCqvHe+KONfcM0RVUXbU3lVVcU4wML1wsI1zqouoKMiO+nN6LlhaSlVRdjB5nops5bMx88ywP0BLr4/qCXoMOZnpLCrOjdtahqNt/QwMj/KNx/dHnBsaGeVrj73B2QsLIxaEwViF1dBCeo1dg8H1F9XFORGzkkYDSlNI8PB84pJl5GSmcf3ayMBwQW0ZIkTNMzR3D0Uknj3eWobB4VG213Vy6RnlUR8Xqignk61fuYorz6ma8rHJYoHBmHnmZI8zx3/xJFU9V1TGZ2aSfzTAic4BCnMyeGBHQ8Qn8h88f4SGrkFu/71zg8XzQnk9hi5372eff5TWXl9wGKy6OCeikF5L7xD+gIYNJQHcsH4xO//26oiAAc76jbOqCnk1ysykaOUwPFVFTlmMV451MDwa4NJVp8csSQsMxswzY2sYovcYwF3L0NY/ZXG5qTR1DzEyqnz+ylVUFGTzD7/aG3zNkz1DfGfLYa5ZXcVbVkYfl/fG9b0egzds4130q0ty6fX56R0am7nk1T2KFgBys9InbOvGZaXsqOtkNKQiq6rSNFmPoTibll4fz73ZSlZ6GhcuS93hoVhYYDBmnmkKrmGYuMewvCKf3iE/bX2z23PZ23zn3EVF/NU1Z7GjvouHX3cWd/3L4wfwj2qwXlE04wvpeesTvLZ7eZLQBHRwDUPpxIEvmguXldHn8/NGU0/wWPfgCD5/IGJGkmdhUQ6jAeVXrzeyYWkJeVmnx6aYFhiMmWe86Z1T9Rhg9sX0jrU7z19Wns/7LqjhvMVFfP3X+9l6pJ1f7DjBxy9dFtyxLZqsjDQKszOCyWdvcVto8hnGgl3oYyaadTURb6HbqyF5huYJ1jB4vOMtvT4uO02GkcACgzHzTmPXIMW5meRHKfLmWRGssjq7BHR9xwBZGWksLMohLU24/V2raeoe4pYfvkJFQTaffdsZU75GaX5WMMfgrXL2PsF7PYamkAT0ic5ByvKzYv70vqgkl8Ulufzg+aM89FoDowGdcA2DJ/T4VNNUTyUWGIyZZ5q6hiacqupZXJpLZrrMei1DXXs/tWV5pLmJ5U3Ly3jnmmqGRgJ84ZozKcyZuiREaV5mMMfQ2DVIZWE22RlOrsD7xD6+xxAtvzAd//6BdRTmZPD5/32Nd3zzWX6xowGILIfh8Y4X5WSwZnHxjN4zFZ0eA2LGmGlr7I6cyjleepqwtDx/1msZ6toHwjbfAfjqe87jirMquXFDzQTPCleanzUWGLrDL/pZGWlUFGSHzUxq6Bxg1YLCGbV384pyHvuTy3hibzPffvogv3LzId6WnuOVF2STkSa8ZWVF1FlVpyoLDMbMM41dg1zgVvmczGyL6akqde0DETOOSvOzeP/GJdN+nbK8LA61OENaDZ2DnFMdvhBuUUlOMG+iqjR0DfK2sxbMuN1pacJ1a6q5ZvVCfrOvme7BkWAPZbz0NOGfb1zDeadRbwEsMBgzrwwM++keHJlWYnZFRT7PHmhlNKAz+jTc2utjcGQ0aqmLWJTkOTkG76J/5TnhF/2FRTnBANbRP8zQSCBiDcNMpKUJ154XuRhuvFiC3KnCcgzGzCNe8nb8zm3RLK/IZ3g0EFz3EKs6b/OdWQYGr5Bec88QPn8gIqgtKskN5hjGz1oyM2OBwZh5ZLINesbzpqzONAHtVWddNsl01OkodVc/721w1heMDwwLi3Pocxe5eWsY4tFjmM8sMBgzj3jTOqczlLS80l3L0DqzKav1HQOkyew/vZe5i9z2NHYDka83NmV1KLjquaYkdSuXngosMBgzjzR2DQU3sJlKZUE2hdkZHJ7hzKS6dqf0dVbG7C4z3urnPW6PITIwjC1ya+gapCA7g6JcS5/OhgUGY+aRxq5BKguyyUyf+r++iLBhaSn/t+04z70Z+97qde39LC2b3TASjBXS29vYTW5mOiXj9kUI9hi6BjnR6UxnnWgHNTM9FhiMmUeauifeoCeab35wPSsqC/jDH2+LOTjUdQzMekYSQGm+EwictudEXPSrinIQGesxWH5h9iwwGDOPNHYPTlo8b7yy/Czu+8OLWOkGh2enGRy6B0boGhiJT2Bwh5Igem4kuMite5CGzgGbkRQHFhiMOU2d7BliZHRsr2RVpbFrcNLiedGUusHhjMoCPvXjbWw50DLlc+o6nLzEZAXypisz3SmkBxMnsquLczjY0kfPkD/mqqomUqL3fL5bRFpEZE/Isf8nIg0i8pr7dX3IuS+LyCEROSAi1ySybcaczvyjAa7+5nN86sfbgvsLdA2MMDQSuQ5gOkrzs7jXDQ633buDnpD9D6Lxym3Ho8fgvT9MHhj2NLizliwwzFqieww/Aq6Ncvyb7t7O61X1MQARORf4ELDafc53RGTiXTXMvDYa0FlvInM6O9LWT/fgCFsOtPIfTx4AxsptL5rGjKRoSvOz+Ocb19A/PMpDOxsmfWydW267tiy+gWGioFZdnMvIqPPvwYaSZi+hgUFVnwMiN1GN7gbgf1XVp6pHgUPApoQ1zpyyAgHlxu+8yNceeyPZTUlZe905/29ZWc5/P3OYX+9uGlv1PIsL59qaYlYvKuLerfWTBua69gEWFGbHbeOaMncm0sSBYSzYWY9h9pKVY/isiOxyh5q8vfAWA8dDHnPCPRZBRG4VkW0isq21NfZpdObU9uzBVl4/0c3+5t5kNyVl7W3oITsjjbtuuZANtSX8xc9eD+YGqmNIPo8nInz4olr2N/dG7N8cqq49PjOSPF4CesKhJPd4VkYaFfnRK6Ga6UtGYLgDWAmsB5qAf4/1BVT1TlXdqKobKytPn12TzPT84PkjALTPctvJ09nexh7OXlhIblY6d3zkAvKzM7h3az2Z6TLrC+e71y0iLyud+7bWT/iYuo7+uCSePWX5WZMuzPN6DItLcoN7P5iZm/PAoKonVXVUVQPA9xkbLmoAQssU1rjHjAna19jDi4faycpIC9boN+FUlb2N3Zy7yCkFXVWUw3c/cgGZ6cLC4pxZXzgLczK5Yf0ifrWrMWoSenB4lJM9voh9GGbjoxcv5dsfOn/CVdShgcHM3pwHBhEJrWP7XsCbsfQw8CERyRaR5cAq4JW5bp9JbXe9cJTczHR+f8NiOvqHLQEdxYnOQXqG/KxeNLZvwQVLS7nj5gv4y6vPist7fHjTUoZGAvwyShK63q2qurQifj2GpeX5vHvdognPe4vcLDDEx7QDg4h8XkSKxHGXiOwQkauneM79wEvAWSJyQkQ+CfyLiOwWkV3A24A/A1DVvcD/AfuAx4HbVHV0hj9XzFSVf37sDXaf6J6rtzQxaukZ4uHXG/jAxppgSeg+nz/ZzUo5exudmkKhgQHgqnOruGF91LRdzNbUFLNmcTH3RUlCezOS4tljmEpmehpfvPZsPrjp9NsbIRlimTLwCVX9tru+oBT4KPAT4DcTPUFVb4py+K5JHv9PwD/F0Ka48fkDfO85Z+x6Tc3ptRvT6eLHL9XhDygfv2Q52+o6AejsH5nWvsHzyb7GbtIEzl5YNPWDZ+GmTbV85cHd7DzexYba0uDxeK9hmK7PvHXlnL7f6SyWoSRvYPJ64CfuJ/zTJssz7K4Qbe4ZmuKRJhkGh0f5n611vOOcKpZV5FPuzmtv7/cluWWpZ29jDysrC8jNSuwyoHevX0R+lCR0XUc/xbmZwaqo5tQTS2DYLiK/wQkMT4hIIRCY4jmnDN+IGxi6LTCkop/vOEHXwAifunwFMFZxczYJ6O11nTy572Rc2pdK9jX1RAwjJUJBdgY3nL+YR3Y18sTeZroGnL9FvKeqmrkXy1DSJ3GmmB5R1QERKQc+npBWJYHP76QzTlqPIeUEAsrdLxxlXU0xG5c6QxZlwR7DzAPDNx7fzytHO/jqe87jI5uXxqWtydbRP0xT9xCrF83NcOjH37KMR15v5NM/2Y64w1cnOga44uwFUz/ZpKxpBwZVDYjIMuAjIqLAC6r6YMJaNsd8/rGhJFW1eu4pZG9jD0fb+vm3968L/l3KC2bfYzjU0kdWehp/88s9KPDR0yA4eCue56LHALCqqpBX/+YqXj/ezctH2tl6tJ26dmXTstKpn2xS1rQDg4h8BzgDuN899GkRuUpVb0tIy+aYN5Q0NBKgZ9BPcZ4lNFPF9jqnqsrFK8uDx3Iz08mexVqGjv5hOvqH+cI1Z7GzvpO//eUeUOWjFy+LR5OTxpuRdO4cBQaA7Ix0Ni0vY9PyMmCVfbA6DcQylPR24Bx156aJyD04U0tPC95QEkBTz6AFhhSyo76LqqLssOJvIkJ5ftakq5+PtPaxorIg6rlDLc4+xucuKuIPL1vObffu4G8f2gtwSgeHvY09LC7JTWri14LCqS+W5PMhoDbk/hLgYHybkzzeUBJYAjrV7KjvZENtacQFp6wgi44JZiW9eqyDt//7s+ys74x63gsMZ1QWkJ2RznduvoArz17A7Q/vPaX//nsbu+dsGMmcvmIJDIXAGyKyRUSewektFInIwyLycGKaN3dCA4MloFNHS+8QJzoHw+bJe8rysyccSjrS6lz4d9R3RT1/qKWP3Mz04ErZrIw0/uTKVajCtrrpFgSOD1WNy0K9fp+fo239c5Z4NqevWIaSbk9YK1KAb2RsKKm52+bGT8Q/GiBjGhvJx8uOui4ANiwtiThXnp8VDADjNbmf+r1k7HiHWvtYUZkfVjfonOoisjPS2FHXxbvWTlx+Id4e293MbfftoLYsj80ryti8opzNK8pjLo+9v7kH1bnNL5jTUyyzkp4VkaXAKlV9SkRygQxVPS1qH4cNJVmPIah7YIRXjnXw8pF2Xj7SzhtNPdSW5XHR8nI2r3QuYrFuFRmLnfWdZKZL1E/BZflZE/YYvF7fPjcZO97hlj42jps5k5WRxtqaYnZMMPyUKK8e6yAnM42zFhby+J5m/m/bCUTgno9v4vIzp189eKJSGMbEKpZZSZ8CbgXKcMpm1wDfBa5MTNPmlhcYCrMzbCjJ9eS+k3z6J9sIqHPR3FBbwqcuX8GR1n5+vaeJn25zts9IH1etc11NMQ/88SVxacOO+k5WLyomJzNyFW9ZfhYDw6MMjYxGnPd6DAdb+iLO9/v8NHQN8qHKyLo6G2pLufvFo1FfM1EONPdy9sIivv8HGxkNKPube7jpzpd5dFdTbIGhoYfSvMywTWuMmYlYhpJuwymRvRVAVQ+KyGmzimXYDQxLK/JO6eRjPG050EJeVgY/uGUj65eUhF0ovQvY1iMdYZ/aXz/RxfMH2+gdmn0No2F/gF0nurn5oujrC8pDFrmNr6rZ3D1EVnoaw6MB3jzZy9qakuC5I61OkbczFkTOWDq/tpSR546wt7GbC5aWzar906GqHDjZyzvOqQKcILt6UTGblpfz8tH2mF5rb1M3qxcV26wgM2uxDBb7VDV4BRCRDOC0qXnsTVddWpZvPQbX7oZu1iwuZvOK8ohPz94F7BOXLucvrzkr+HXTJmfimldIbTbeaOrB5w9EzS9ASFmMKFNWm7qH2Oyue9g7bjjpUKsz+hktMHjv5eU2xvvqI/v4yUvHptH66Wnrc9ZTnLWwMOz4xSvLqWsfoLFrcFqvMzIa4M3mPhtGMnERS2B4VkS+AuSKyDuAnwG/Skyz5p43lFRbnkd7/3DYuob5aNgfYH9Tb8yVZpe5u3Ydc0svz4Y31h9tRhKMrX4eX0hvcHiU7sERLlpeRkF2RkSe4VBLH+lpEnWHsQWFOdSU5kbNM7T0DnH3i0e5+8VjM/lxojrgbk969rjAsHmF01vZOs1ew8GTfQyPBizxbOIilsDwJaAV2A18GnhMVf86Ia1KAm/lc61bQ76lZ37PTHrzZC/DowHWLI4xMFQ4v79jbfEIDF0sLMqZcHZOmbtF5fgEtDd5oLo4h3OriyJmJh1q6WNped6Eu4FtqC1lR31nxD4DT+xpJqBwtK2fE52z7xGBM5MI4MxxgeGchUUU52by0uHpBYaXjjiPu2CplaIwsxdLYPicqn5fVd+vqu9T1e+LyOcT1rI55vOPkpWeFkzczffhpN0NzsU01sCQl5XBgsJsjsVhKGlHXeeEw0gwcYXVpm5n+GVhcQ7nLirijaZeRgNjF/lDLX2cMcGKaIANtSWc7PHROC7X9OjuJopznbzJi4fapv1z3PncYfY0RJ82++bJXioKsqgoCN+HOS1N2LS8jJePTG9NxZYDLZyxoICaUqtqamYvlsBwS5RjH4tTO5LO5w+QlZEW3Gx8vk9Z3d3QTWFOxozKJy+ryJ91j6GlZ4iGrugL2zxFORlkpktEhVVv8kB1cS6rFxUxODLKUbc9I6MB6toHWFU1cWDwks476saGk1p6h9h6tINbLl7KgsJsXjg0vU/yB5p7+dpj+/n+80cmPD8+v+C5eEU59R0DNEyRZxgY9rP1SAdvO2v6M5iMmcyUgUFEbhKRXwHLvVXO7tcWYNKPMyJyt4i0iMiekGP/KiL7RWSXiDwoIiXu8WUiMigir7lf353djxYbn3+U7Iw0Fha5gWGez0za4yaeZzLDZXl5/qxzDN4Y//mTBAYRoTQvKyL57E1VXViUE1z/4A0n1bX34w9o1MSz5+zqQnIy08LyDE/saUYV3rVuEZeeUcGLh9oIBKaee/HAzhMAvHS4PWJoKhBQ3jzZx5lV0QPD5hVO8nzrkcmD0O8OtTM8GuCKs06bSYImyabTY/gd8O/Afve79/XnwDVTPPdHwLXjjj0JnKeqa4E3gS+HnDusquvdr89Mo21x4xsJkJ2RRnFuJtkZafN6KCmYeI5xGMmztCKPtr5heodGZtyGHfVdZKWncd7iyZOpZflZET2Gkz1DFOdmkpuVzqqqArLS04IJ6IMnvRpJ0S/G4OwfvLamJKycxiO7mli1oIAzqwq55IwKOvqHeaM5+uI5z2hAeWhnI9kZabT0+oK9Fs/xzgEGR0YjEs+esxcWUpybyctTBIYtb7aQl5UesWDPmJmaMjCoap2qbgGuAp5X1WeBJpwFbpN+nFTV5xjXq1DV36iqVxjmZfd1ks7nD5CdmY6IsLA4h+Z5nHz2Es/nzTAwLHdn+8xmyuqOuk7OW1xEdsbki8zKoxTSa+oeCuaKMtPTOHNhQXDKqlc8b+WCyBlJoTbUlrK3oZuhkVFaeoZ45VgH16+pBuDSVRUAvHBw8jzDS4fbae4Z4rNvOwMgIl+w352RNFGPIS1NuGh5WTCxHI2qsuVAK5ecUTHl78qY6Yolx/AckCMii4HfAB/F6RHMxieAX4fcXy4iO0XkWRG5bKInicitIrJNRLa1trbOsgkObygJoKooh5NJHEpq6/PRksQei5d4XhvjVFXPsgrnojv+E/J0DfsD7GronjS/4IlWSK+5eyiYKwJYXV3M3sZuVJVDrX0sLsklL2vytZ0bakvwB5TdDd08vtcZRnrnWicwVBXlsGpBAS9MkYB+YOcJCnMy+NTlK1hQmB3xyf/AFIEBnOGk4x2DE86COtzax4nOQa6w/IKJo1gCg6jqAHAj8B1VfT+weqZvLCJ/DfiBe91DTUCtqp6PM0x1n4hEHUdQ1TtVdaOqbqysjM9/CJ8/EAwMC4tykpp8/sLPXuez9+9M2vvvOtFNUU5GcOpurLyEdd0M8wz7mnoY9gfYMI2pl+VRhpKauoeCuSKA1YuL6BwYoal7iEMtfaycJL/g8d57R11n2DCS59JVFbx6rIOhkejrXQaG/Ty+p5l3rqkmJzOdzSvKeflIeJ7hwMleasvyyM+eOEh5mxNtnWB20pYDzgcjyy+YeIopMIjIxcDNwKPusRn1XUXkY8C7gJu9jX9U1aeq7e7t7cBh4MyZvP5MDPsDwa64M5Q0FJEsnCv7m3vjsg5gpvY0dLOmZualFfKyMqgqyuZo28yGkrxP1tPrMWTRO+QPljQZ9gdo7/eF9RjOrXY+X+xp6OZw6+RTVT0VBdnUluXxxN5mXj3WEewteC49o4KhkUDYzKVQT+xtZmB4lBs3OCOlm1eUR+QZDjT3TtpbADirqpCSvInzDM8caOHMqoKIkiDGzEYsgeHzOIniB1V1r4isAJ6J9Q1F5Frgr4B3uz0Q73iliKS7t1cAq4Doc/wSwMkxjA0lDfsDdA3MPHk6UwPDfpq6h2jt8zEyGpj6CbMw7A9EBD+ff5T9zT0zzi94ls1iZtKvdzextqY47OI+EW8tQ+eA02to6R1ClbBCcudUFyECT71xkqGRwKQzkkJtqHUS0KrwzjXhgeGiFeVkpMmEw0kP7GigpjSXjW7Pw1vJ7OULfH5nCu1EiWfPZHmGfp+fV492Wm/BxN20A4OqPqeq71bVb7j3j6jqn3jnReS/xj9HRO4HXgLOEpETIvJJ4P/D2fTnyXHTUi8HdonIa8DPgc+o6pztmBKaYwhOWU3CcNIx91O2KrT0Ji4BPjQyylu+/lu+9VT4JnxvNvcxMqoznpHkWV6RP6OhpOMdA7x+ojuY6J1KsJCeO2XVm2a8MKQUeH52BsvL8/n1nmYgeo2kaLzhpDOrClg17pN9QXYG59eWRA0MJ3uGePFQG+89f3Fwv4flFflUFWUHE9CHW/oZDeiEaxhCbV5RzonOQY53hPfAfnfYnaYaQwVWY6YjnjuuRNRZVtWbVLVaVTNVtUZV71LVM1R1yfhpqar6C1Vd7R7boKpzWofJma7qDSU5q1CTERhChxoSuZbilaMdtPX5uGPLYepDZg8FE8+LS2b1+kvL82c0ZfWx3U1A5Cf0iYxf/Ry6hiHUuYuK6B1yJsNNv8fgBIaJgtQlZ1Swu6GbroHwHMdDrzUQUHjv+YuDx0QkLM9w4KQzS2o6gSGYZzga/jnpmQMt5Gels3FZ4qvAmvll7rbiSnHeymdwhpKApMxMOto2tiNZIgPDlgOtZGWkkZ4m/POv3wge393QRXFuJkvKZjdmvTxYMym2PMOj7jDSkmkmvscX0vPWn4wfhvIWupXlZwWDyVRWLyri2x9azx9etiLq+ctWVaBKRD2jB3Y0sH5JCSvG5TI2ryintdfHkbZ+9jf3kpkuLK+YfNoswJkLCinNy+TO5w7z4qE2VBVV5Vl3mupENZ+MmSn7F+UKHUpaUJi8oaQjbf0UuLNUvJo/ibDlQAsXryjnj69Yya/3NAeTm7tnseI5lDdlNZY8w/GOAXad6J52bwEiC+k1dQ+Rl5VOUU74TB+vHPV0Es8eEeGG9YuDf4/x1taUUJCdwXMH23jzZC8/fukYn/nJdvY39/L7GxZHPN5byfzykXbebO5lZWUBmdPYJjUtTfjae9fQM+jn5h9s5QPfe4l7t9bT0DVo+QWTEPEMDKf07iCh01WzMtKoKMhKyurno239rFlcTE5mWsJ6DPXtAxxp6+eKsyr51OUrWFySy9//ah+Dw6McaO6ddeIZnH0tILYqq4+6w0jTzS8AFOdmIjIWGLw1DOMDWzAwTFIjKVaZ6WlsXlHO/a/Uc/U3n+P2h/ay60QXN22q5fcviFy3uaw8L5hnmKxGUjTXralmyxeu4B9uWM3xjkH+5pdOlRlbv2ASIZYd3AAQkbzQ2UQhvh2H9iSNb8RZ+eypKspJSr2ko239vHNNNU3dgwnrsWx5swVw5r7nZKbzpevO5nP37+QfH90Xl8QzQG5WOguLcjgaQ4/h0V1NrIthGAmcDYNK88bWMjR1D0bkFwDKC7L5wjVn8dY4J2o/89YVVBZms6G2hM0ryqkpzZ2wtyUiXLyinGcOtNI9OBJTYADIyUznDy5exgc2LuFn20/QMzgyYUlyY2Yjlj2f3wL8ACgAakVkHfBpVf1jAFX9UUJaOAdUNWwoCZzk5fiyy4nW2T9M18AIyyvyOdzal7DA9Mz+FpaV5wXHt9+1tpp7fneM+7bWAzNf8Tzesoq8aZfFqG8fYHdDN1+5/uyY36csf6yQ3skeHxetiJ6Mvc0tTRFPG5eVxZT83byinF++1ghEbs4zXTmZ6Xx0c/TtTo2Jh1iGkr6JUzTPW4T2Os4U01OeP6AElLDAUFWcM+dDSUfcYZcVlflUF+cGZ9jE09DIKC8daQ8bmxYRbv+9cwFnaKamND6fQpeVR5bfVlXueuFoxIItbxjpuvOmP4zkKcvPomNgmNGAcrJnKGwNQ6rx8gwweSkMY5IppqEkVT0+rpt8Wux/6a2aDS1CVl2UQ0f/MEMjoxH7HSeKN1V1eUUBC93AFAhocC58PLx8pJ2hkQBvHTc2vbamhNvethL/qMZtM/llFfm09w/TMzRCUY63wU07//jIPkTgc29fxeevXEV6mvDY7ibWLSmJaRjJU56fxcGWPtr7fPgDGraGIdUsLc9jYVEO/T6/rVY2KSuWwHDcHU5SEcnEWQn9xhTPOSV4+z17K5/B6TGAs8Vn7Qw2q5mJo219ZKQJNaW5LCzKwR9Q2vuHqSzMnvrJ07TlQCvZGWlcHPLJ1fOFa2IfxpmMt/9zXdsAa2qKUVW+9dSbVBfncPHKcv7z6YO8erSDv7j6zBkPI4HbY+gfnnANQyoRET5w4RJae4fiFoCNibdYAsNncBLMi4EGnAqrtyWiUXPN53c6PuNzDOBMWZ27wNBPbVkemekhO8l1D8U1MDz7ZisXryyfk16Qt//z0fZ+1tQU88KhNrbVdfKP7zmPj25eysUryvnbh/bw/u+9BMQ2GylUeX4WnQPDNLo7naXyUBLAn79jzkqAGTMj0w4MqtqGU0DvtOMbiRxKSsYWn0da+4MJYe/i1tQ9yJo4JYOPtfVztK2fWy6em8Rl6JRVp7dwkOriHD6w0ZnK+f6NS1i/pITP3reTBUXZM96vuCw/C1V4wy1jPZ0aS8aYiU0ZGNwaSBOWGQ2tl3Sq8oaSQleQzvXq50BAOdbez6VnOJvAJCIwbTkwNk11LuRmpVNdnMOx9n6eP9jGdre3EBqAV1UV8vifXsY0dsmcUFmB06Pa19hNVnoaZXnTW9lsjIluOrOStgHbgRxgA3DQ/VoPnBb/A6MNJRXlZJCbmT5nPYbmniGGRgIsr3Q+ZVfkZ5ORJnGdsvrMgVaWV+QHVyXPhaXleRxr6+dbT73JopDeQigRIX0WCXavkN7exh4WFGXHNVlvzHw0ZY9BVe8BEJE/Ai71tuV0q6I+n9jmzQ1flFlJY1t8zk1gGJuR5Fy009IkrovshkZGeflIOzdtqo3L603X8op8fvrqcQIKXx3XW4gXr/ZRU/cQF9q+x8bMWizrGEqB0B3VCtxjp7xgjiEz/NdRXZzDgebeOdmwJ7iGoWKsZMPC4py4rWXYcqAFnz/A286e29o6y8rzCSgsKs7h/VF6C/FQHlIUL5WnqhpzqoglMHwd2CkiPxKRe4AdwNcS06y5FW0oCZyyyYda+njqjZaEt+Foaz+5melUFY3NQIpnj+XuF4+xuCSXS1ZGTlNNpJVu0brb3n5GwjarLw0JDKk+I8mYU0EsG/X8ELgIeBD4BXCxN8x0qos2lAROYFhanse3nnoz4b2Go219LK/ID5vbvtAdSprte+860cUrRzv4+CXLyJhGNc94uuKsSu64eQMfujBxQ1iZ6WnBaqqpvIbBmFNFrFeJTcBlOKUwLox/c5Jjoh5DRnoan3v7KvY29vDkvpMJbcPRtv5g4tlTXZzD4MgoPYP+Wb32XS8cpSA7gw9euGRWrzMTGelpXLemelbJ5ekod2cm2VRVY2Zv2oFBRL6Os9p5n/v1JyJyWgwlDUdZ+ex5z/pFLCvP41tPHUxYr2HYH+B45yArx80W8i5yTT0z35ehsWuQR3Y18aELl1DolqU4HXkJaAsMxsxeLD2G64F3qOrdqno3cC3wrsmeICJ3i0iLiOwJOVYmIk+KyEH3e6l7XETkP0XkkIjsEpENM/mBZmKioSQY6zXsa+rhNwnqNRzvHGA0oFF7DMCsEtD3/O4YqsrHLlk2myamPC8wWI7BmNmLdSipJOT2dJbj/ggngIT6EvC0qq4CnnbvA1wHrHK/bgXuiLFtMza28jn6r+MGt9fw7QT1Go62jhXPC+UtspvplNU+n5/7XqnnujXVM15VfKooz88iTaCyIH7lQ4yZr2IJDP9M+Kyk7cA/TfYEVX0O6Bh3+AbAS1rfA7wn5PiP1fEyUCIiMyueEyMvxzDR3rmhvYYn9sa/1xBcw1Ae3mNYUJiDyMwDw8+2Had3yM8fXrp81m1Mde9au4hbL18558l1Y05HscxKuh/YDDzA2Kykn87gPatUtcm93QxUubcXA8dDHnfCPRZBRG4VkW0isq21tXUGTQjn8wdIE8iYJEF6w/pFLK/I51tPvYl/NDDr9wx1pK2P8vwsivPCcwDOFqPZMwoMowHl7hePcsHSUs6vPS2Wm0zq0lUVfOm6+FaHNWa+iiX5fAnQo6oP4yx0+ysRmVU1NnXGZWIem1HVO1V1o6purKyc/VaNzn7P6ZOWQc5IT+Mvrz6L/c29/MsTB2b9nqFCi+eNV12cQ1MMaxlUleMdA/zXbw9yvGNwXvQWjDHxFUvZ7TuAde6Wnn8O3AX8GHhrjO95UkSqVbXJHSryVo81AKHzKWvcYwnnGxmNOiNpvHeureblI0u587kjrF5UxA3ro3ZoYqKqHG3rn3Av4qqiHOqmsW/yK0c7+N9X69l6pIMGt/z0uiUlXL164azbaIyZX2IZkPW7n/BvAP5bVf8bmMnehA8Dt7i3bwEeCjn+B+7spM1Ad8iQU0I5PYbp/Sr+9l3nsmlZGV/8xS72NnaHnVNVXjnaMe2hH1XlX584QEuvj/W1JVEfU108db2kweFRPvGjV/nt/hbWLSnmH25YzW/+7HIe/KO3JHz9gDHm9BNLj6FXRL4MfAS4XETSgEknxovI/cAVQIWInAD+Dqe0xv+JyCeBOuAD7sMfw5kSewgYAD4eQ9tmxRtKmo6sjDT+++YNvPv/e4Fbf7ydX33uUkrzMtnyZivfeuogrx/v4uIV5dx/6+ZJX0dV+ZcnDnDHlsPctKmWmyZYGbywOIeeIT/9Pj/52dH/XL/Z1+zMQPrURbxlZcW0fg5jjJlILIHhg8CHgU+qarOI1AL/OtkTVPWmCU5dGeWxSpJ2hPP5R6fdYwCoLMzmux+5gPd/7yX+8J5XGVV4/XgXi0tyueqcBTz1RgtHWvtYUVkQ9fmhQeHDF9Xy1RvOm7BUdHXIvgwrJ3i9B3c2sKg4h83L57YOkjHm9BTLrKRmVf0PVX3evV+vqj9OXNPmzrA/MK0cQ6h1S0r42nvXsKO+i/Y+H1+/cQ3P/OUVfO3GNWSkCfe/Uh/1earKNx53gsLNUwQFmHotQ0vvEM+92cp7zl9s+xAYY+JiOju4vaCql4pIL84MIgn9rqpFk77AKSCWoaRQ77ughvVLiqktyw+ugVhQmMM7zq3i59tP8JfXnBXxug/saOC7zzpB4R+nCAoA1W4Z6YkCw8OvNRJQuHHD7BPhxhgD0+gxqOql7vdCVS0a/z3xTUw830iArBkujDpjQWHEwrgPX1RL58AIj+9pDjve7/Pzjcf3s66meFpBAcaqhU5UfvvBnQ2srSnmjAUzmQdgjDGRYroaisgGEfkTEfmciJyfqEbNNZ9/etNVp+uSlRXUluVx39bw4aQ7thympdfH7b+3etrDPrlZ6ZTkZdLUHVlI70BzL3sbe7jxfOstGGPiJ5YFbrfjlLAoByqAH4nI3ySqYXMplumq05GWJnxo0xK2Hu3gcGsfAMc7Brjz+SPcsH4RFyyNbSXywgm2+Hxg5wky0oTfW7coLu02xhiIrcdwM3Chqv6dqv4dTnmMjyamWXNrpjmGybz/giVOEtrtNXz91/tJE/jitbGXbYi2k9toQHloZyNvPbMyuBeBMcbEQyyBoREIrWmczRytTE4030hs01Wno7Iwm2tWL+TnO07w/MFWHt3dxGfeupJFJbHvSRxtkdtLh9tp7hnixg2J2UfZGDN/xXI17Ab2utVVfwjsAbrcPRT+MzHNmxu+GUxXnY6bNtXSNTDCH/3PDqqLc/j05Stn9DoLi3Jp6xvmW0+9yUuH2xkaGeWBnScozMngynMWxLnVxpj5LpYFbg+6X54t8W1K8iRiKAngLSvLWVqeR137AP/03vPIzZrZe1x17gKefKOZbz99ENWDZGWkEQgo799YQ05m/NttjJnfph0YVPUeEckFalU1vuVFkyzWlc/TlZYmfOGas3jxUBvvnkWCePWiYh753GV0D47w6tEOXj7Szr6mHj5+iVVONcbE37QDg4j8HvBvQBawXETWA/+gqu9OUNvmRCCgjIxqQnoM4Gwg86618Zk1VJybyVXnVnHVuVVTP9gYY2Yolo/J/w/YBHQBqOprwIq4t2iODbub7iQix2CMMaeiWK6GI6raPe5YfLcySwJvv+eZrnw2xpjTTSzJ570i8mEgXURWAX8C/C4xzZo73n7P1mMwxhhHLFfDzwGrAR9wH8701T9NQJvmlM/vDiUlKMdgjDGnmlhmJQ0Af+1+RRCR/1LVz8WrYXMl2GNIwKwkY4w5FcXzanhJHF9rzgyNeD0GCwzGGAPxDQynpOBQki0UM8YYILbkc9yIyFnAT0MOrQBuB0qATwGt7vGvqOpjiWyLDSUZY0y4eAaGae8r6a6cXg8gIuk4xfgeBD4OfFNV/y2O7ZrUWPLZAoMxxsAMhpJEpEhEom0X9u0ZtuFK4LCq1s3w+bPiG7FZScYYEyqWjXouFJHdwC5gj4i8LiIXeOdV9UczbMOHgPtD7n9WRHaJyN0iEnVHGxG5VUS2ici21tbWaA+ZNlv5bIwx4WK5Gt4F/LGqLlPVpcBtwA9n8+YikgW8G/iZe+gOYCXOMFMT8O/Rnqeqd6rqRlXdWFlZOZsm4Btxcgy28tkYYxyxXA1HVfV5746qvgD4Z/n+1wE7VPWk+5onVXVUVQPA93FqMyXU2KwkCwzGGAPTSD6LyAb35rMi8j2cYR8FPsjs92S4iZBhJBGpVtUm9+57cTYDSihb+WyMMeGmMytp/HDO7e53wQkQMyIi+cA7gE+HHP4Xt5y3AsfGnUsIm65qjDHhpgwMqvo2ABHJAX4fWBbyvBkHBlXtB8rHHfvoTF9vpny28tkYY8LEso7hlzh7MewAvJ3pZxwYUoXPHyArIw2RaS/DMMaY01osgaFGVa9NWEuSJFHbehpjzKkqlivi70RkTcJakiQ+f8ASz8YYEyKWHsOlwMdE5CjOngwCqKquTUjL5ohvJGA9BmOMCRFLYLguYa1IIp9/1NYwGGNMiFg26klKLaNEG/YHbNWzMcaEmPdXRJ8/YHsxGGNMCAsMNivJGGPCzPsrojMrad7/GowxJmjeXxGdWUk2lGSMMR4LDDYryRhjwsz7K6INJRljTLh5f0W0lc/GGBPOAsOIzUoyxphQ8/6KaENJxhgTbl5fEVWV4VELDMYYE2peXxFHRhVVbOWzMcaEiKWIXlyJyDGgFxgF/Kq6UUTKgJ/i7BJ3DPiAqnYmqg22racxxkRK9hXxbaq6XlU3uve/BDytqquAp937CePz27aexhgzXqpdEW8A7nFv3wO8J5FvNhYYbCjJGGM8yQwMCvxGRLaLyK3usSpVbXJvNwNViWyAb8QdSrKVz8YYE5S0HANwqao2iMgC4EkR2R96UlVVRDTaE91AcitAbW3tjBtgQ0nGGBMpaVdEVW1wv7cADwKbgJMiUg3gfm+Z4Ll3qupGVd1YWVk54zbYUJIxxkRKSmAQkXwRKfRuA1cDe4CHgVvch90CPJTIdgSHkqzHYIwxQckaSqoCHhQRrw33qerjIvIq8H8i8kmgDvhAIhvh9RiyLDAYY0xQUgKDqh4B1kU53g5cOVftsKEkY4yJNK8/Kg97gcFmJRljTNC8viLaymdjjIk0r6+INpRkjDGR5ndgsFlJxhgTYV5fEX2WYzDGmAjz+ooYnK6aPq9/DcYYE2ZeXxF9/lEy0oQMCwzGGBM0r6+IvhHbvc0YY8ab11dFnz9gq56NMWaceX1V9PlHbaqqMcaMM68Dw7A/YDOSjDFmnHl9VfT5LcdgjDHjzeurohMYbCjJGGNCzfPAMGo9BmOMGWdeXxV9I5ZjMMaY8eb1VdGGkowxJtI8Dww2lGSMMePN66uizUoyxphISbkqisgSEXlGRPaJyF4R+bx7/P+JSIOIvOZ+XZ/IdvhGbOWzMcaMl5Q9nwE/8BequkNECoHtIvKke+6bqvpvc9EIW/lsjDGRkhIYVLUJaHJv94rIG8DiuW6HDSUZY0ykpF8VRWQZcD6w1T30WRHZJSJ3i0jpBM+5VUS2ici21tbWGb+3lcQwxphISb0qikgB8AvgT1W1B7gDWAmsx+lR/Hu056nqnaq6UVU3VlZWzui9/aMB/AG1oSRjjBknaYFBRDJxgsK9qvoAgKqeVNVRVQ0A3wc2Jer9h0fdbT1tKMkYY8Ika1aSAHcBb6jqf4Qcrw552HuBPYlqg2/EAoMxxkSTrFlJlwAfBXaLyGvusa8AN4nIekCBY8CnE9UAb7/n7EwbSjLGmFDJmpX0AiBRTj02V23w+UcB6zEYY8x48/aq6PUYbIGbMcaEm7dXxbEcgw0lGWNMqPkbGGwoyRhjopq3V8Vg8tkCgzHGhJm3V8Vhm5VkjDFRzdvAUJafxfVrFlKen5XsphhjTEpJ1jqGpFu3pITv3HxBspthjDEpZ972GIwxxkRngcEYY0wYCwzGGGPCWGAwxhgTxgKDMcaYMBYYjDHGhLHAYIwxJowFBmOMMWFEVZPdhlkRkVagboZPrwDa4ticRLK2Joa1NTGsrYkRz7YuVdXKaCdO+cAwGyKyTVU3Jrsd02FtTQxra2JYWxNjrtpqQ0nGGGPCWGAwxhgTZr4HhjuT3YAYWFsTw9qaGNbWxJiTts7rHIMxxphI873HYIwxZhwLDMYYY8LM28AgIteKyAEROSQiX0p2e0KJyN0i0iIie0KOlYnIkyJy0P1emsw2ekRkiYg8IyL7RGSviHzePZ5y7RWRHBF5RURed9v69+7x5SKy1f238FMRSYlt/UQkXUR2isgj7v1UbecxEdktIq+JyDb3WMr9/QFEpEREfi4i+0XkDRG5OBXbKiJnub9P76tHRP50rto6LwODiKQD/w1cB5wL3CQi5ya3VWF+BFw77tiXgKdVdRXwtHs/FfiBv1DVc4HNwG3u7zIV2+sD3q6q64D1wLUishn4BvBNVT0D6AQ+mbwmhvk88EbI/VRtJ8DbVHV9yBz7VPz7A3wbeFxVzwbW4fx+U66tqnrA/X2uBy4ABoAHmau2quq8+wIuBp4Iuf9l4MvJbte4Ni4D9oTcPwBUu7ergQPJbuME7X4IeEeqtxfIA3YAF+GsJM2I9m8jie2rcf/jvx14BJBUbKfblmNAxbhjKff3B4qBo7iTblK5rePadzXw4ly2dV72GIDFwPGQ+yfcY6msSlWb3NvNQFUyGxONiCwDzge2kqLtdYdnXgNagCeBw0CXqvrdh6TKv4VvAX8FBNz75aRmOwEU+I2IbBeRW91jqfj3Xw60Aj90h+h+ICL5pGZbQ30IuN+9PSdtna+B4ZSmzseFlJpnLCIFwC+AP1XVntBzqdReVR1Vp3teA2wCzk5uiyKJyLuAFlXdnuy2TNOlqroBZ2j2NhG5PPRkCv39M4ANwB2qej7Qz7ihmBRqKwBuHundwM/Gn0tkW+drYGgAloTcr3GPpbKTIlIN4H5vSXJ7gkQkEyco3KuqD7iHU7a9AKraBTyDMyRTIiIZ7qlU+LdwCfBuETkG/C/OcNK3Sb12AqCqDe73Fpxx8E2k5t//BHBCVbe693+OEyhSsa2e64AdqnrSvT8nbZ2vgeFVYJU7yyMLp6v2cJLbNJWHgVvc27fgjOUnnYgIcBfwhqr+R8iplGuviFSKSIl7OxcnF/IGToB4n/uwpLdVVb+sqjWqugzn3+ZvVfVmUqydACKSLyKF3m2c8fA9pODfX1WbgeMicpZ76EpgHynY1hA3MTaMBHPV1mQnVpKY0LkeeBNnjPmvk92ecW27H2gCRnA+5XwSZ4z5aeAg8BRQlux2um29FKc7uwt4zf26PhXbC6wFdrpt3QPc7h5fAbwCHMLpsmcnu60hbb4CeCRV2+m26XX3a6/3fykV//5uu9YD29x/A78ESlO4rflAO1AccmxO2molMYwxxoSZr0NJxhhjJmCBwRhjTBgLDMYYY8JYYDDGGBPGAoMxxpgwFhiMmQER+QcRuSoOr9MXj/YYE082XdWYJBKRPlUtSHY7jAllPQZjXCLyEXe/htdE5Htuwb0+Efmmu3/D0yJS6T72RyLyPvf21939KHaJyL+5x5aJyG/dY0+LSK17fLmIvOTuX/DVce//BRF51X2Ot1dEvog86u4hsUdEPji3vxUzH1lgMAYQkXOADwKXqFNkbxS4GWf16TZVXQ08C/zduOeVA+8FVqvqWsC72P8XcI977F7gP93j38Yp4rYGZ3W79zpXA6tw6gytBy5wi9FdCzSq6jpVPQ94PM4/ujERLDAY47gSZ0OUV92y3FfilHsIAD91H/M/OCVAQnUDQ8BdInIjzoYq4BTnu8+9/ZOQ513CWO2bn4S8ztXu106cfSLOxgkUu4F3iMg3ROQyVe2e3Y9pzNQypn6IMfOC4HzC/3LYQZG/Hfe4sKScqvpFZBNOIHkf8FmcaqiTiZbYE+CfVfV7ESdENuDUn/qqiDytqv8wxesbMyvWYzDG8TTwPhFZAME9i5fi/B/xKpp+GHgh9EnuPhTFqvoY8Gc420UC/A6nMio4Q1LPu7dfHHfc8wTwCff1EJHFIrJARBYBA6r6P8C/4pSJNiahrMdgDKCq+0Tkb3B2IkvDqWx7G85mLpvccy04eYhQhcBDIpKD86n/z93jn8PZKewLOLuGfdw9/nngPhH5IiElk1X1N26e4yWnkjl9wEeAM4B/FZGA26Y/iu9Pbkwkm65qzCRsOqmZj2woyRhjTBjrMRhjjAljPQZjjDFhLDAYY4wJY4HBGGNMGAsMxhhjwlhgMMYYE+b/B2UqhzWMhd0DAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 194.000, steps: 194\n",
            "Episode 2: reward: 198.000, steps: 198\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 192.000, steps: 192\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 187.000, steps: 187\n",
            "Episode 12: reward: 187.000, steps: 187\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 192.000, steps: 192\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f825dcfdcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Warm up 55 & gamma 0.99\n"
      ],
      "metadata": {
        "id": "7kKP9-5qLrPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=55, # how many steps are waited before starting experience replay,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy,\n",
        "               gamma=0.99) \n",
        "\n",
        "dqn.compile(Adam(learning_rate=.0003), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kDC9xFQuD-th",
        "outputId": "4c249676-5423-4d17-aee4-9db2dbfea7bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   19/10000: episode: 1, duration: 0.298s, episode steps:  19, steps per second:  64, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   46/10000: episode: 2, duration: 0.022s, episode steps:  27, steps per second: 1237, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.593 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   65/10000: episode: 3, duration: 1.303s, episode steps:  19, steps per second:  15, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 2.501514, mae: 25.493119, mean_q: 51.051331, mean_eps: 0.730000\n",
            "  197/10000: episode: 4, duration: 0.947s, episode steps: 132, steps per second: 139, episode reward: 132.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 4.095597, mae: 24.675640, mean_q: 49.378635, mean_eps: 0.412750\n",
            "  277/10000: episode: 5, duration: 0.579s, episode steps:  80, steps per second: 138, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 4.464411, mae: 24.536321, mean_q: 49.066797, mean_eps: 0.100337\n",
            "  341/10000: episode: 6, duration: 0.470s, episode steps:  64, steps per second: 136, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.453 [0.000, 1.000],  loss: 3.978156, mae: 25.272487, mean_q: 50.565374, mean_eps: 0.100000\n",
            "  422/10000: episode: 7, duration: 0.606s, episode steps:  81, steps per second: 134, episode reward: 81.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 3.613063, mae: 24.970020, mean_q: 50.048717, mean_eps: 0.100000\n",
            "  485/10000: episode: 8, duration: 0.457s, episode steps:  63, steps per second: 138, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.460 [0.000, 1.000],  loss: 3.388465, mae: 25.157882, mean_q: 50.362496, mean_eps: 0.100000\n",
            "  546/10000: episode: 9, duration: 0.451s, episode steps:  61, steps per second: 135, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 2.873972, mae: 24.930734, mean_q: 49.969750, mean_eps: 0.100000\n",
            "  603/10000: episode: 10, duration: 0.424s, episode steps:  57, steps per second: 134, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.456 [0.000, 1.000],  loss: 5.110294, mae: 24.869167, mean_q: 49.668997, mean_eps: 0.100000\n",
            "  660/10000: episode: 11, duration: 0.404s, episode steps:  57, steps per second: 141, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.456 [0.000, 1.000],  loss: 5.519461, mae: 25.037353, mean_q: 50.033860, mean_eps: 0.100000\n",
            "  717/10000: episode: 12, duration: 0.414s, episode steps:  57, steps per second: 138, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.456 [0.000, 1.000],  loss: 4.736715, mae: 25.065714, mean_q: 50.029260, mean_eps: 0.100000\n",
            "  769/10000: episode: 13, duration: 0.393s, episode steps:  52, steps per second: 132, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 5.185188, mae: 25.326081, mean_q: 50.582992, mean_eps: 0.100000\n",
            "  833/10000: episode: 14, duration: 0.466s, episode steps:  64, steps per second: 137, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.453 [0.000, 1.000],  loss: 2.783193, mae: 24.905842, mean_q: 49.877086, mean_eps: 0.100000\n",
            "  895/10000: episode: 15, duration: 0.463s, episode steps:  62, steps per second: 134, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 3.231267, mae: 24.912661, mean_q: 49.833695, mean_eps: 0.100000\n",
            "  969/10000: episode: 16, duration: 0.529s, episode steps:  74, steps per second: 140, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 3.369749, mae: 25.059023, mean_q: 50.126395, mean_eps: 0.100000\n",
            " 1032/10000: episode: 17, duration: 0.454s, episode steps:  63, steps per second: 139, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.460 [0.000, 1.000],  loss: 4.001779, mae: 24.954180, mean_q: 49.883361, mean_eps: 0.100000\n",
            " 1118/10000: episode: 18, duration: 0.803s, episode steps:  86, steps per second: 107, episode reward: 86.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 3.205512, mae: 25.031354, mean_q: 50.049139, mean_eps: 0.100000\n",
            " 1173/10000: episode: 19, duration: 0.576s, episode steps:  55, steps per second:  96, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 3.131633, mae: 25.111675, mean_q: 50.178031, mean_eps: 0.100000\n",
            " 1234/10000: episode: 20, duration: 0.645s, episode steps:  61, steps per second:  95, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 4.288194, mae: 24.759171, mean_q: 49.411626, mean_eps: 0.100000\n",
            " 1295/10000: episode: 21, duration: 0.647s, episode steps:  61, steps per second:  94, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 5.660323, mae: 25.249715, mean_q: 50.291461, mean_eps: 0.100000\n",
            " 1347/10000: episode: 22, duration: 0.437s, episode steps:  52, steps per second: 119, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 2.762280, mae: 24.682822, mean_q: 49.317797, mean_eps: 0.100000\n",
            " 1418/10000: episode: 23, duration: 0.531s, episode steps:  71, steps per second: 134, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 2.627178, mae: 24.968602, mean_q: 49.903625, mean_eps: 0.100000\n",
            " 1476/10000: episode: 24, duration: 0.442s, episode steps:  58, steps per second: 131, episode reward: 58.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.466 [0.000, 1.000],  loss: 2.841092, mae: 24.734148, mean_q: 49.446462, mean_eps: 0.100000\n",
            " 1544/10000: episode: 25, duration: 0.494s, episode steps:  68, steps per second: 138, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 2.895623, mae: 24.889643, mean_q: 49.717244, mean_eps: 0.100000\n",
            " 1623/10000: episode: 26, duration: 0.597s, episode steps:  79, steps per second: 132, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 2.089493, mae: 24.824890, mean_q: 49.605667, mean_eps: 0.100000\n",
            " 1697/10000: episode: 27, duration: 0.532s, episode steps:  74, steps per second: 139, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 1.790580, mae: 25.055616, mean_q: 50.116168, mean_eps: 0.100000\n",
            " 1761/10000: episode: 28, duration: 0.474s, episode steps:  64, steps per second: 135, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.453 [0.000, 1.000],  loss: 1.599870, mae: 25.139696, mean_q: 50.272458, mean_eps: 0.100000\n",
            " 1838/10000: episode: 29, duration: 0.581s, episode steps:  77, steps per second: 132, episode reward: 77.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 2.708936, mae: 24.764782, mean_q: 49.429917, mean_eps: 0.100000\n",
            " 1939/10000: episode: 30, duration: 0.747s, episode steps: 101, steps per second: 135, episode reward: 101.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 3.094988, mae: 24.859383, mean_q: 49.629264, mean_eps: 0.100000\n",
            " 2068/10000: episode: 31, duration: 0.935s, episode steps: 129, steps per second: 138, episode reward: 129.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 2.516532, mae: 24.563735, mean_q: 49.079152, mean_eps: 0.100000\n",
            " 2122/10000: episode: 32, duration: 0.389s, episode steps:  54, steps per second: 139, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 3.359306, mae: 24.563092, mean_q: 49.010813, mean_eps: 0.100000\n",
            " 2192/10000: episode: 33, duration: 0.524s, episode steps:  70, steps per second: 134, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 2.367361, mae: 24.578506, mean_q: 49.064755, mean_eps: 0.100000\n",
            " 2257/10000: episode: 34, duration: 0.459s, episode steps:  65, steps per second: 142, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 1.572786, mae: 24.325713, mean_q: 48.642573, mean_eps: 0.100000\n",
            " 2351/10000: episode: 35, duration: 0.701s, episode steps:  94, steps per second: 134, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 1.987096, mae: 24.508799, mean_q: 48.928970, mean_eps: 0.100000\n",
            " 2489/10000: episode: 36, duration: 1.000s, episode steps: 138, steps per second: 138, episode reward: 138.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 1.588703, mae: 24.401524, mean_q: 48.760692, mean_eps: 0.100000\n",
            " 2544/10000: episode: 37, duration: 0.381s, episode steps:  55, steps per second: 144, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 2.264712, mae: 24.094272, mean_q: 48.086079, mean_eps: 0.100000\n",
            " 2626/10000: episode: 38, duration: 0.607s, episode steps:  82, steps per second: 135, episode reward: 82.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 2.292710, mae: 24.442158, mean_q: 48.724601, mean_eps: 0.100000\n",
            " 2705/10000: episode: 39, duration: 0.712s, episode steps:  79, steps per second: 111, episode reward: 79.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 1.509139, mae: 24.207466, mean_q: 48.303583, mean_eps: 0.100000\n",
            " 2905/10000: episode: 40, duration: 2.054s, episode steps: 200, steps per second:  97, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.507081, mae: 24.229686, mean_q: 48.389165, mean_eps: 0.100000\n",
            " 3035/10000: episode: 41, duration: 0.966s, episode steps: 130, steps per second: 135, episode reward: 130.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.477 [0.000, 1.000],  loss: 1.690908, mae: 23.873767, mean_q: 47.617676, mean_eps: 0.100000\n",
            " 3108/10000: episode: 42, duration: 0.544s, episode steps:  73, steps per second: 134, episode reward: 73.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 2.554325, mae: 23.680340, mean_q: 47.151113, mean_eps: 0.100000\n",
            " 3172/10000: episode: 43, duration: 0.483s, episode steps:  64, steps per second: 133, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.453 [0.000, 1.000],  loss: 2.522968, mae: 23.862854, mean_q: 47.577866, mean_eps: 0.100000\n",
            " 3240/10000: episode: 44, duration: 0.513s, episode steps:  68, steps per second: 133, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.456 [0.000, 1.000],  loss: 2.941187, mae: 23.752166, mean_q: 47.324762, mean_eps: 0.100000\n",
            " 3345/10000: episode: 45, duration: 0.759s, episode steps: 105, steps per second: 138, episode reward: 105.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 0.653828, mae: 23.343594, mean_q: 46.646642, mean_eps: 0.100000\n",
            " 3485/10000: episode: 46, duration: 1.014s, episode steps: 140, steps per second: 138, episode reward: 140.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 2.036523, mae: 23.521467, mean_q: 46.907514, mean_eps: 0.100000\n",
            " 3650/10000: episode: 47, duration: 1.203s, episode steps: 165, steps per second: 137, episode reward: 165.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 1.327263, mae: 22.846206, mean_q: 45.508696, mean_eps: 0.100000\n",
            " 3728/10000: episode: 48, duration: 0.582s, episode steps:  78, steps per second: 134, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 0.733512, mae: 23.323497, mean_q: 46.575874, mean_eps: 0.100000\n",
            " 3821/10000: episode: 49, duration: 0.654s, episode steps:  93, steps per second: 142, episode reward: 93.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 0.539073, mae: 22.324269, mean_q: 44.521163, mean_eps: 0.100000\n",
            " 3929/10000: episode: 50, duration: 0.784s, episode steps: 108, steps per second: 138, episode reward: 108.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 2.118830, mae: 22.532289, mean_q: 44.741590, mean_eps: 0.100000\n",
            " 4028/10000: episode: 51, duration: 0.718s, episode steps:  99, steps per second: 138, episode reward: 99.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 0.888889, mae: 22.273333, mean_q: 44.295769, mean_eps: 0.100000\n",
            " 4135/10000: episode: 52, duration: 0.773s, episode steps: 107, steps per second: 138, episode reward: 107.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 1.761251, mae: 22.569598, mean_q: 44.882255, mean_eps: 0.100000\n",
            " 4222/10000: episode: 53, duration: 0.617s, episode steps:  87, steps per second: 141, episode reward: 87.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.460 [0.000, 1.000],  loss: 1.758039, mae: 21.952163, mean_q: 43.631342, mean_eps: 0.100000\n",
            " 4422/10000: episode: 54, duration: 1.913s, episode steps: 200, steps per second: 105, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 1.202699, mae: 21.813782, mean_q: 43.498907, mean_eps: 0.100000\n",
            " 4507/10000: episode: 55, duration: 0.900s, episode steps:  85, steps per second:  94, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 1.337633, mae: 21.890764, mean_q: 43.656467, mean_eps: 0.100000\n",
            " 4602/10000: episode: 56, duration: 0.768s, episode steps:  95, steps per second: 124, episode reward: 95.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 1.069315, mae: 21.963910, mean_q: 43.822788, mean_eps: 0.100000\n",
            " 4767/10000: episode: 57, duration: 1.236s, episode steps: 165, steps per second: 133, episode reward: 165.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.479 [0.000, 1.000],  loss: 0.788634, mae: 21.557019, mean_q: 43.063966, mean_eps: 0.100000\n",
            " 4922/10000: episode: 58, duration: 1.150s, episode steps: 155, steps per second: 135, episode reward: 155.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.523 [0.000, 1.000],  loss: 0.887172, mae: 21.629495, mean_q: 43.265847, mean_eps: 0.100000\n",
            " 5122/10000: episode: 59, duration: 1.417s, episode steps: 200, steps per second: 141, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 0.979631, mae: 21.628837, mean_q: 43.114964, mean_eps: 0.100000\n",
            " 5224/10000: episode: 60, duration: 0.743s, episode steps: 102, steps per second: 137, episode reward: 102.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.461 [0.000, 1.000],  loss: 0.426916, mae: 21.528310, mean_q: 43.054627, mean_eps: 0.100000\n",
            " 5386/10000: episode: 61, duration: 1.233s, episode steps: 162, steps per second: 131, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.475 [0.000, 1.000],  loss: 1.108037, mae: 21.896520, mean_q: 43.741745, mean_eps: 0.100000\n",
            " 5495/10000: episode: 62, duration: 0.802s, episode steps: 109, steps per second: 136, episode reward: 109.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 0.833744, mae: 21.412494, mean_q: 42.741287, mean_eps: 0.100000\n",
            " 5680/10000: episode: 63, duration: 1.380s, episode steps: 185, steps per second: 134, episode reward: 185.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 0.557768, mae: 21.149713, mean_q: 42.265980, mean_eps: 0.100000\n",
            " 5794/10000: episode: 64, duration: 0.862s, episode steps: 114, steps per second: 132, episode reward: 114.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.456 [0.000, 1.000],  loss: 0.549331, mae: 21.477139, mean_q: 42.927514, mean_eps: 0.100000\n",
            " 5994/10000: episode: 65, duration: 1.856s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 1.430060, mae: 21.306829, mean_q: 42.530483, mean_eps: 0.100000\n",
            " 6149/10000: episode: 66, duration: 1.483s, episode steps: 155, steps per second: 105, episode reward: 155.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 1.197244, mae: 21.373549, mean_q: 42.717080, mean_eps: 0.100000\n",
            " 6302/10000: episode: 67, duration: 1.127s, episode steps: 153, steps per second: 136, episode reward: 153.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 0.790536, mae: 21.605009, mean_q: 43.197313, mean_eps: 0.100000\n",
            " 6502/10000: episode: 68, duration: 1.434s, episode steps: 200, steps per second: 139, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.276479, mae: 21.297939, mean_q: 42.372610, mean_eps: 0.100000\n",
            " 6702/10000: episode: 69, duration: 1.443s, episode steps: 200, steps per second: 139, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 1.067029, mae: 21.693076, mean_q: 43.384253, mean_eps: 0.100000\n",
            " 6893/10000: episode: 70, duration: 1.393s, episode steps: 191, steps per second: 137, episode reward: 191.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 1.178433, mae: 21.716268, mean_q: 43.303441, mean_eps: 0.100000\n",
            " 7093/10000: episode: 71, duration: 1.496s, episode steps: 200, steps per second: 134, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.913597, mae: 21.837249, mean_q: 43.605411, mean_eps: 0.100000\n",
            " 7293/10000: episode: 72, duration: 1.478s, episode steps: 200, steps per second: 135, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 1.109976, mae: 22.547450, mean_q: 45.159678, mean_eps: 0.100000\n",
            " 7493/10000: episode: 73, duration: 1.533s, episode steps: 200, steps per second: 130, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 1.346447, mae: 22.790395, mean_q: 45.674297, mean_eps: 0.100000\n",
            " 7693/10000: episode: 74, duration: 2.060s, episode steps: 200, steps per second:  97, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.127342, mae: 23.295630, mean_q: 46.624027, mean_eps: 0.100000\n",
            " 7893/10000: episode: 75, duration: 1.520s, episode steps: 200, steps per second: 132, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.653345, mae: 23.845294, mean_q: 47.811731, mean_eps: 0.100000\n",
            " 8093/10000: episode: 76, duration: 1.455s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 2.580130, mae: 24.243270, mean_q: 48.536715, mean_eps: 0.100000\n",
            " 8293/10000: episode: 77, duration: 1.485s, episode steps: 200, steps per second: 135, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.360653, mae: 24.764665, mean_q: 49.701555, mean_eps: 0.100000\n",
            " 8493/10000: episode: 78, duration: 1.505s, episode steps: 200, steps per second: 133, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.889926, mae: 25.304882, mean_q: 50.806117, mean_eps: 0.100000\n",
            " 8693/10000: episode: 79, duration: 1.444s, episode steps: 200, steps per second: 138, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 2.987324, mae: 25.610480, mean_q: 51.363678, mean_eps: 0.100000\n",
            " 8893/10000: episode: 80, duration: 1.480s, episode steps: 200, steps per second: 135, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.772328, mae: 26.365377, mean_q: 53.035031, mean_eps: 0.100000\n",
            " 9093/10000: episode: 81, duration: 1.532s, episode steps: 200, steps per second: 131, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 2.762181, mae: 26.991394, mean_q: 54.298379, mean_eps: 0.100000\n",
            " 9293/10000: episode: 82, duration: 2.057s, episode steps: 200, steps per second:  97, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 3.796290, mae: 27.332223, mean_q: 54.875742, mean_eps: 0.100000\n",
            " 9493/10000: episode: 83, duration: 1.524s, episode steps: 200, steps per second: 131, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.738834, mae: 27.979122, mean_q: 56.046438, mean_eps: 0.100000\n",
            " 9693/10000: episode: 84, duration: 1.462s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 3.472286, mae: 28.665566, mean_q: 57.543269, mean_eps: 0.100000\n",
            " 9893/10000: episode: 85, duration: 1.455s, episode steps: 200, steps per second: 137, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 4.238681, mae: 29.073450, mean_q: 58.337754, mean_eps: 0.100000\n",
            "done, took 79.066 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f825d60a820>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Warm up 55 & gamma 0.99 but with nb_steps 7000\n"
      ],
      "metadata": {
        "id": "TRgApdoRLxr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = SequentialMemory(limit=10000, window_length=1)\n",
        "\n",
        "policy =  LinearAnnealedPolicy(inner_policy=EpsGreedyQPolicy(0.2), \n",
        "                               attr='eps',            \n",
        "                               value_max=1.,\n",
        "                               value_min=.1, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=200)\n",
        "\n",
        "# Q-Network\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "# add extra layers here\n",
        "model.add(Flatten())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igKU4hAzL2s4",
        "outputId": "9fe4a2da-4f41-41d7-e08f-574406b29f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_9 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 16)                80        \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 386\n",
            "Trainable params: 386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=55, # how many steps are waited before starting experience replay,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy,\n",
        "               gamma=0.99) \n",
        "\n",
        "dqn.compile(Adam(learning_rate=.0003), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=7000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f24b008f-f2a1-4d4b-d3da-3dccb295c540",
        "id": "3kM3jcH_Lxr5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 7000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   12/7000: episode: 1, duration: 0.953s, episode steps:  12, steps per second:  13, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   73/7000: episode: 2, duration: 3.550s, episode steps:  61, steps per second:  17, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 4.070912, mae: 12.237512, mean_q: 23.960834, mean_eps: 0.712000\n",
            "  107/7000: episode: 3, duration: 0.336s, episode steps:  34, steps per second: 101, episode reward: 34.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 5.885544, mae: 12.342272, mean_q: 24.045447, mean_eps: 0.597250\n",
            "  172/7000: episode: 4, duration: 0.593s, episode steps:  65, steps per second: 110, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 5.256099, mae: 12.318729, mean_q: 24.012841, mean_eps: 0.374500\n",
            "  224/7000: episode: 5, duration: 0.474s, episode steps:  52, steps per second: 110, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 5.262971, mae: 12.463736, mean_q: 24.339831, mean_eps: 0.135135\n",
            "  286/7000: episode: 6, duration: 0.600s, episode steps:  62, steps per second: 103, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 5.522846, mae: 12.530791, mean_q: 24.406029, mean_eps: 0.100000\n",
            "  329/7000: episode: 7, duration: 0.396s, episode steps:  43, steps per second: 108, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 5.418550, mae: 12.529652, mean_q: 24.477452, mean_eps: 0.100000\n",
            "  490/7000: episode: 8, duration: 1.420s, episode steps: 161, steps per second: 113, episode reward: 161.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 6.217068, mae: 12.741379, mean_q: 24.900501, mean_eps: 0.100000\n",
            "  538/7000: episode: 9, duration: 0.422s, episode steps:  48, steps per second: 114, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 4.198472, mae: 12.845118, mean_q: 25.286681, mean_eps: 0.100000\n",
            "  738/7000: episode: 10, duration: 2.195s, episode steps: 200, steps per second:  91, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 6.132947, mae: 12.939629, mean_q: 25.307670, mean_eps: 0.100000\n",
            "  833/7000: episode: 11, duration: 1.106s, episode steps:  95, steps per second:  86, episode reward: 95.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 6.783958, mae: 13.217153, mean_q: 25.864988, mean_eps: 0.100000\n",
            "  988/7000: episode: 12, duration: 1.345s, episode steps: 155, steps per second: 115, episode reward: 155.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 6.070838, mae: 13.290027, mean_q: 26.122570, mean_eps: 0.100000\n",
            " 1055/7000: episode: 13, duration: 0.580s, episode steps:  67, steps per second: 116, episode reward: 67.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.448 [0.000, 1.000],  loss: 6.655739, mae: 13.251857, mean_q: 25.951195, mean_eps: 0.100000\n",
            " 1140/7000: episode: 14, duration: 0.754s, episode steps:  85, steps per second: 113, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 5.521475, mae: 13.421029, mean_q: 26.447142, mean_eps: 0.100000\n",
            " 1340/7000: episode: 15, duration: 1.773s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.613829, mae: 13.584341, mean_q: 26.803405, mean_eps: 0.100000\n",
            " 1522/7000: episode: 16, duration: 1.630s, episode steps: 182, steps per second: 112, episode reward: 182.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 5.834026, mae: 13.887250, mean_q: 27.458463, mean_eps: 0.100000\n",
            " 1699/7000: episode: 17, duration: 1.603s, episode steps: 177, steps per second: 110, episode reward: 177.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 5.798488, mae: 14.002141, mean_q: 27.722879, mean_eps: 0.100000\n",
            " 1899/7000: episode: 18, duration: 1.740s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 6.246608, mae: 14.241626, mean_q: 28.253361, mean_eps: 0.100000\n",
            " 2099/7000: episode: 19, duration: 2.315s, episode steps: 200, steps per second:  86, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 5.954243, mae: 14.475589, mean_q: 28.685960, mean_eps: 0.100000\n",
            " 2299/7000: episode: 20, duration: 1.918s, episode steps: 200, steps per second: 104, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 6.354595, mae: 14.876755, mean_q: 29.525388, mean_eps: 0.100000\n",
            " 2455/7000: episode: 21, duration: 1.413s, episode steps: 156, steps per second: 110, episode reward: 156.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 7.257182, mae: 15.028842, mean_q: 29.708278, mean_eps: 0.100000\n",
            " 2655/7000: episode: 22, duration: 1.848s, episode steps: 200, steps per second: 108, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 5.426870, mae: 15.088217, mean_q: 29.954245, mean_eps: 0.100000\n",
            " 2831/7000: episode: 23, duration: 1.590s, episode steps: 176, steps per second: 111, episode reward: 176.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 6.358040, mae: 15.075935, mean_q: 29.928666, mean_eps: 0.100000\n",
            " 3024/7000: episode: 24, duration: 1.687s, episode steps: 193, steps per second: 114, episode reward: 193.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.482 [0.000, 1.000],  loss: 5.244378, mae: 15.299751, mean_q: 30.522980, mean_eps: 0.100000\n",
            " 3224/7000: episode: 25, duration: 1.742s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 6.620882, mae: 15.426076, mean_q: 30.684042, mean_eps: 0.100000\n",
            " 3408/7000: episode: 26, duration: 2.155s, episode steps: 184, steps per second:  85, episode reward: 184.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 4.475284, mae: 15.630171, mean_q: 31.348590, mean_eps: 0.100000\n",
            " 3608/7000: episode: 27, duration: 1.946s, episode steps: 200, steps per second: 103, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 5.246284, mae: 15.902116, mean_q: 31.933914, mean_eps: 0.100000\n",
            " 3808/7000: episode: 28, duration: 1.727s, episode steps: 200, steps per second: 116, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 5.396105, mae: 16.164830, mean_q: 32.475147, mean_eps: 0.100000\n",
            " 4008/7000: episode: 29, duration: 1.802s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 4.299708, mae: 16.657479, mean_q: 33.605624, mean_eps: 0.100000\n",
            " 4208/7000: episode: 30, duration: 1.745s, episode steps: 200, steps per second: 115, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.570843, mae: 17.082150, mean_q: 34.346694, mean_eps: 0.100000\n",
            " 4408/7000: episode: 31, duration: 1.818s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 5.340768, mae: 17.500827, mean_q: 35.291467, mean_eps: 0.100000\n",
            " 4608/7000: episode: 32, duration: 1.800s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 3.786279, mae: 17.905670, mean_q: 36.279945, mean_eps: 0.100000\n",
            " 4808/7000: episode: 33, duration: 2.548s, episode steps: 200, steps per second:  78, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 5.621196, mae: 18.485133, mean_q: 37.327915, mean_eps: 0.100000\n",
            " 5008/7000: episode: 34, duration: 1.817s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 4.589054, mae: 18.728802, mean_q: 37.911874, mean_eps: 0.100000\n",
            " 5208/7000: episode: 35, duration: 1.781s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 3.073481, mae: 19.281600, mean_q: 39.140777, mean_eps: 0.100000\n",
            " 5408/7000: episode: 36, duration: 1.835s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 3.065338, mae: 19.744553, mean_q: 40.058445, mean_eps: 0.100000\n",
            " 5608/7000: episode: 37, duration: 1.805s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 5.851674, mae: 20.190638, mean_q: 40.799794, mean_eps: 0.100000\n",
            " 5808/7000: episode: 38, duration: 1.795s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 3.350317, mae: 20.398860, mean_q: 41.307023, mean_eps: 0.100000\n",
            " 6008/7000: episode: 39, duration: 2.129s, episode steps: 200, steps per second:  94, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 3.991830, mae: 20.895579, mean_q: 42.321509, mean_eps: 0.100000\n",
            " 6208/7000: episode: 40, duration: 2.195s, episode steps: 200, steps per second:  91, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 3.961758, mae: 21.290897, mean_q: 43.079026, mean_eps: 0.100000\n",
            " 6408/7000: episode: 41, duration: 1.809s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 4.298685, mae: 21.521705, mean_q: 43.500808, mean_eps: 0.100000\n",
            " 6608/7000: episode: 42, duration: 1.775s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 4.452201, mae: 21.819671, mean_q: 44.147835, mean_eps: 0.100000\n",
            " 6808/7000: episode: 43, duration: 1.777s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 6.510055, mae: 22.183354, mean_q: 44.742025, mean_eps: 0.100000\n",
            "done, took 70.011 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f825b1a9a30>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Warm up 55 & gamma 0.99 but with nb_steps 6000"
      ],
      "metadata": {
        "id": "l7sv425SRGnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=55, # how many steps are waited before starting experience replay,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy,\n",
        "               gamma=0.99) \n",
        "\n",
        "dqn.compile(Adam(learning_rate=.0003), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=6000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "urdQLNlVMC3e",
        "outputId": "34fa79a3-5939-42df-bd3d-e66a8d8b329e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 6000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   21/6000: episode: 1, duration: 1.401s, episode steps:  21, steps per second:  15, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n",
            "   41/6000: episode: 2, duration: 0.023s, episode steps:  20, steps per second: 855, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   63/6000: episode: 3, duration: 3.620s, episode steps:  22, steps per second:   6, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.777946, mae: 22.876723, mean_q: 46.157059, mean_eps: 0.734500\n",
            "  263/6000: episode: 4, duration: 1.764s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.084045, mae: 23.262863, mean_q: 46.961567, mean_eps: 0.312692\n",
            "  463/6000: episode: 5, duration: 1.791s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.508859, mae: 23.744461, mean_q: 47.798727, mean_eps: 0.100000\n",
            "  663/6000: episode: 6, duration: 1.768s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 5.287035, mae: 23.941380, mean_q: 48.263032, mean_eps: 0.100000\n",
            "  863/6000: episode: 7, duration: 2.244s, episode steps: 200, steps per second:  89, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 4.285153, mae: 24.263479, mean_q: 48.942425, mean_eps: 0.100000\n",
            " 1063/6000: episode: 8, duration: 2.079s, episode steps: 200, steps per second:  96, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 4.179882, mae: 24.606970, mean_q: 49.642594, mean_eps: 0.100000\n",
            " 1263/6000: episode: 9, duration: 1.787s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 3.655188, mae: 25.143758, mean_q: 50.740770, mean_eps: 0.100000\n",
            " 1463/6000: episode: 10, duration: 1.766s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 5.311664, mae: 25.457675, mean_q: 51.295675, mean_eps: 0.100000\n",
            " 1663/6000: episode: 11, duration: 1.790s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 6.822479, mae: 25.852605, mean_q: 51.971875, mean_eps: 0.100000\n",
            " 1863/6000: episode: 12, duration: 1.788s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 3.922833, mae: 26.061188, mean_q: 52.499652, mean_eps: 0.100000\n",
            " 2063/6000: episode: 13, duration: 1.765s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 7.465173, mae: 26.427112, mean_q: 53.021292, mean_eps: 0.100000\n",
            " 2263/6000: episode: 14, duration: 2.508s, episode steps: 200, steps per second:  80, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 6.817984, mae: 26.891890, mean_q: 53.993927, mean_eps: 0.100000\n",
            " 2463/6000: episode: 15, duration: 1.764s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 9.479422, mae: 27.181783, mean_q: 54.342340, mean_eps: 0.100000\n",
            " 2663/6000: episode: 16, duration: 1.817s, episode steps: 200, steps per second: 110, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 7.061114, mae: 27.525387, mean_q: 55.208430, mean_eps: 0.100000\n",
            " 2863/6000: episode: 17, duration: 1.835s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 5.346756, mae: 27.907473, mean_q: 56.037101, mean_eps: 0.100000\n",
            " 3063/6000: episode: 18, duration: 1.767s, episode steps: 200, steps per second: 113, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 9.230570, mae: 28.229966, mean_q: 56.496042, mean_eps: 0.100000\n",
            " 3263/6000: episode: 19, duration: 1.840s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.490 [0.000, 1.000],  loss: 7.941558, mae: 28.245941, mean_q: 56.475424, mean_eps: 0.100000\n",
            " 3463/6000: episode: 20, duration: 2.134s, episode steps: 200, steps per second:  94, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 7.985822, mae: 28.497556, mean_q: 56.944335, mean_eps: 0.100000\n",
            " 3663/6000: episode: 21, duration: 2.151s, episode steps: 200, steps per second:  93, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 7.020543, mae: 28.588566, mean_q: 57.180589, mean_eps: 0.100000\n",
            " 3863/6000: episode: 22, duration: 1.757s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 7.483552, mae: 28.913604, mean_q: 57.812247, mean_eps: 0.100000\n",
            " 4063/6000: episode: 23, duration: 1.786s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 8.915247, mae: 29.240545, mean_q: 58.340834, mean_eps: 0.100000\n",
            " 4263/6000: episode: 24, duration: 1.838s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.142385, mae: 29.549740, mean_q: 59.066815, mean_eps: 0.100000\n",
            " 4463/6000: episode: 25, duration: 1.794s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 8.409374, mae: 29.953164, mean_q: 59.805424, mean_eps: 0.100000\n",
            " 4663/6000: episode: 26, duration: 1.839s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 8.864973, mae: 30.403853, mean_q: 60.736500, mean_eps: 0.100000\n",
            " 4863/6000: episode: 27, duration: 2.559s, episode steps: 200, steps per second:  78, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 7.831929, mae: 30.522853, mean_q: 61.064305, mean_eps: 0.100000\n",
            " 5063/6000: episode: 28, duration: 1.839s, episode steps: 200, steps per second: 109, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 8.478464, mae: 30.762208, mean_q: 61.483911, mean_eps: 0.100000\n",
            " 5263/6000: episode: 29, duration: 1.755s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 9.682791, mae: 30.806429, mean_q: 61.517484, mean_eps: 0.100000\n",
            " 5463/6000: episode: 30, duration: 1.785s, episode steps: 200, steps per second: 112, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 11.459744, mae: 31.085288, mean_q: 61.957184, mean_eps: 0.100000\n",
            " 5663/6000: episode: 31, duration: 1.757s, episode steps: 200, steps per second: 114, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.505 [0.000, 1.000],  loss: 8.587292, mae: 31.239734, mean_q: 62.402216, mean_eps: 0.100000\n",
            " 5863/6000: episode: 32, duration: 1.795s, episode steps: 200, steps per second: 111, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.510 [0.000, 1.000],  loss: 7.862395, mae: 31.397240, mean_q: 62.756256, mean_eps: 0.100000\n",
            "done, took 61.250 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f825b455310>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9-O-sNoWPu6T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}